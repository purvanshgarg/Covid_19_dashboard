{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d15cc2-3159-4bee-b5c0-cfb78079c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load an empty map\n",
    "# !pip uninstall keplergl\n",
    "# !pip install keplergl\n",
    "# import keplergl\n",
    "# from keplergl import KeplerGl\n",
    "# map_1 = KeplerGl()\n",
    "# map_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "154c9f18-3871-4d48-a9f4-f2eed12b2f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(r'D:\\Covid 19') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "684373a3-0eb0-4ef5-a366-eb7adb06e756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Covid 19'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd22fc9-15b1-4110-b508-5f020c01848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import pydeck as pdk\n",
    "\n",
    "# # Load datasets\n",
    "# cases_df = pd.read_csv(\"covid cases by state_Full Data_data (1).csv\")\n",
    "# testing_df = pd.read_csv(\"Statewise Testing Details_Full Data_data.csv\")\n",
    "# vaccine_df = pd.read_csv(\"COVID-19 India Statewise Vaccine Data.csv\")\n",
    "\n",
    "# # Convert date columns to datetime format\n",
    "# casimport pandas as pd\n",
    "# import numpy as np\n",
    "# import pydeck as pdk\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Load the merged dataset that contains both COVID cases and vaccination data\n",
    "# merged_data = pd.read_csv('merged_covid_vaccine_data.csv')\n",
    "\n",
    "# # Convert date column to datetime\n",
    "# merged_data['Date'] = pd.to_datetime(merged_data['Date'])\n",
    "\n",
    "# # Filter for second wave period (March 2021 to July 2021)\n",
    "# start_date = '2021-03-01'\n",
    "# end_date = '2021-07-31'\n",
    "# wave2_data = merged_data[(merged_data['Date'] >= start_date) & (merged_data['Date'] <= end_date)]\n",
    "\n",
    "# # Calculate rolling averages for smoother trends\n",
    "# def prepare_state_trends(state_data):\n",
    "#     # Sort by date\n",
    "#     state_data = state_data.sort_values('Date')\n",
    "    \n",
    "#     # Calculate 7-day rolling averages\n",
    "#     state_data['Cases_7day_avg'] = state_data['New Cases'].rolling(7).mean()\n",
    "    \n",
    "#     # Calculate daily vaccination rate (first difference of cumulative doses)\n",
    "#     state_data['Daily_Doses'] = state_data['Total Doses Administered'].diff()\n",
    "#     state_data['Doses_7day_avg'] = state_data['Daily_Doses'].rolling(7).mean()\n",
    "    \n",
    "#     return state_data\n",
    "\n",
    "# # Function to create visualization for a specific state\n",
    "# def create_state_vaccination_impact(state_name):\n",
    "#     state_data = wave2_data[wave2_data['State'] == state_name].copy()\n",
    "    \n",
    "#     if len(state_data) < 10:  # Skip if insufficient data\n",
    "#         return None\n",
    "    \n",
    "#     state_data = prepare_state_trends(state_data)\n",
    "    \n",
    "#     # Create a dual-axis plot\n",
    "#     fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    \n",
    "#     # Add new cases trend\n",
    "#     fig.add_trace(\n",
    "#         go.Scatter(\n",
    "#             x=state_data['Date'], \n",
    "#             y=state_data['Cases_7day_avg'],\n",
    "#             name=\"New Cases (7-day avg)\",\n",
    "#             line=dict(color='red', width=2)\n",
    "#         ),\n",
    "#         secondary_y=False\n",
    "#     )\n",
    "    \n",
    "#     # Add vaccination trend\n",
    "#     fig.add_trace(\n",
    "#         go.Scatter(\n",
    "#             x=state_data['Date'], \n",
    "#             y=state_data['Doses_7day_avg'],\n",
    "#             name=\"Daily Vaccinations (7-day avg)\",\n",
    "#             line=dict(color='blue', width=2)\n",
    "#         ),\n",
    "#         secondary_y=True\n",
    "#     )\n",
    "    \n",
    "#     # Add titles and labels\n",
    "#     fig.update_layout(\n",
    "#         title_text=f\"COVID-19 Cases vs. Vaccination Rate: {state_name}\",\n",
    "#         xaxis_title=\"Date\",\n",
    "#         legend=dict(y=0.99, x=0.01, orientation='h'),\n",
    "#         template='plotly_white',\n",
    "#         height=600\n",
    "#     )\n",
    "    \n",
    "#     fig.update_yaxes(title_text=\"New Cases (7-day avg)\", secondary_y=False)\n",
    "#     fig.update_yaxes(title_text=\"Daily Vaccinations (7-day avg)\", secondary_y=True)\n",
    "    \n",
    "#     return fig\n",
    "\n",
    "# # Function to analyze vaccination impact across all states\n",
    "# def analyze_vaccination_impact():\n",
    "#     # Get list of top 10 states by total cases\n",
    "#     case_totals = wave2_data.groupby('State')['Confirmed'].max().nlargest(10)\n",
    "#     top_states = case_totals.index.tolist()\n",
    "    \n",
    "#     # Calculate metrics to measure vaccination impact\n",
    "#     impact_metrics = []\n",
    "    \n",
    "#     for state in top_states:\n",
    "#         state_data = wave2_data[wave2_data['State'] == state].copy()\n",
    "        \n",
    "#         if len(state_data) < 30:  # Skip if insufficient data\n",
    "#             continue\n",
    "            \n",
    "#         state_data = state_data.sort_values('Date')\n",
    "        \n",
    "#         # Get vaccination and case data\n",
    "#         first_record = state_data.iloc[0]\n",
    "#         peak_record = state_data.loc[state_data['New Cases'].idxmax()]\n",
    "#         last_record = state_data.iloc[-1]\n",
    "        \n",
    "#         # Calculate metrics\n",
    "#         pre_vax_cases = first_record['Confirmed']\n",
    "#         peak_cases = peak_record['Confirmed']\n",
    "#         end_cases = last_record['Confirmed']\n",
    "        \n",
    "#         start_vax = first_record['Total Doses Administered'] if not pd.isna(first_record['Total Doses Administered']) else 0\n",
    "#         peak_vax = peak_record['Total Doses Administered'] if not pd.isna(peak_record['Total Doses Administered']) else 0\n",
    "#         end_vax = last_record['Total Doses Administered'] if not pd.isna(last_record['Total Doses Administered']) else 0\n",
    "        \n",
    "#         # Calculate the case decline rate after peak\n",
    "#         days_after_peak = (last_record['Date'] - peak_record['Date']).days\n",
    "#         if days_after_peak > 0:\n",
    "#             case_decline_rate = (peak_cases - end_cases) / days_after_peak\n",
    "#         else:\n",
    "#             case_decline_rate = 0\n",
    "            \n",
    "#         # Calculate vaccination rate\n",
    "#         total_days = (last_record['Date'] - first_record['Date']).days\n",
    "#         if total_days > 0:\n",
    "#             vax_rate = (end_vax - start_vax) / total_days\n",
    "#         else:\n",
    "#             vax_rate = 0\n",
    "        \n",
    "#         impact_metrics.append({\n",
    "#             'State': state,\n",
    "#             'Case_Growth_to_Peak': peak_cases - pre_vax_cases,\n",
    "#             'Case_Decline_After_Peak': end_cases - peak_cases,\n",
    "#             'Daily_Case_Decline_Rate': case_decline_rate,\n",
    "#             'Daily_Vaccination_Rate': vax_rate,\n",
    "#             'Total_Vaccinations': end_vax,\n",
    "#             'Peak_Date': peak_record['Date'],\n",
    "#             'Peak_Cases': peak_record['New Cases']\n",
    "#         })\n",
    "    \n",
    "#     impact_df = pd.DataFrame(impact_metrics)\n",
    "    \n",
    "#     # Create visualization of relationship between vaccination rate and case decline\n",
    "#     fig = px.scatter(\n",
    "#         impact_df, \n",
    "#         x='Daily_Vaccination_Rate', \n",
    "#         y='Daily_Case_Decline_Rate',\n",
    "#         size='Total_Vaccinations',\n",
    "#         color='Peak_Cases',\n",
    "#         hover_name='State',\n",
    "#         text='State',\n",
    "#         color_continuous_scale='Viridis',\n",
    "#         title='Relationship Between Vaccination Rate and COVID-19 Case Decline Rate',\n",
    "#         labels={\n",
    "#             'Daily_Vaccination_Rate': 'Daily Vaccination Rate (doses/day)',\n",
    "#             'Daily_Case_Decline_Rate': 'Daily Case Decline Rate (cases/day)',\n",
    "#             'Total_Vaccinations': 'Total Vaccinations',\n",
    "#             'Peak_Cases': 'Peak Daily Cases'\n",
    "#         },\n",
    "#         size_max=50\n",
    "#     )\n",
    "    \n",
    "#     fig.update_traces(textposition='top center')\n",
    "#     fig.update_layout(height=700, template='plotly_white')\n",
    "    \n",
    "#     return fig, impact_df\n",
    "\n",
    "# # Function to create vaccination distribution analysis\n",
    "# def analyze_vaccination_distribution():\n",
    "#     # Filter the last available record for each state to get final vaccination numbers\n",
    "#     latest_recordsltip={\"html\": \"<b>Cases:</b> {Confirmed}\"}\n",
    "# )\n",
    "\n",
    "# r.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bb856e-693a-4a6e-b5b7-396f0c0e8f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"Statewise Testing Details_Full Data_data.csv\")\n",
    "# df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfdb29c-aa39-4229-a93a-d0f267cca029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62d2b39-720c-4400-90cb-6e8b35efccb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e3dee-333d-4408-a907-cb1190db327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dash_bootstrap_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a3472d5-52c6-4c96-a2cf-e8f1762d8e17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COVID-19 Second Wave Dashboard (March-July 2021)\n",
      "==================================================\n",
      "\n",
      "1. PEAK COVID CASES MAP VISUALIZATION\n",
      "\n",
      "2. VACCINATION PROGRESS MAP\n",
      "COVID-19 Second Wave Dashboard (March-July 2021)\n",
      "==================================================\n",
      "\n",
      "1. PEAK COVID CASES MAP VISUALIZATION\n",
      "\n",
      "2. VACCINATION PROGRESS MAP\n",
      "\n",
      "DETAILED ANALYSIS OF COVID-19 SECOND WAVE (MARCH-JULY 2021)\n",
      "======================================================================\n",
      "\n",
      "Top 5 States by Confirmed Cases:\n",
      "State\n",
      "Maharashtra       6061404\n",
      "Kerala            2924165\n",
      "Karnataka         2843810\n",
      "Tamil Nadu        2479696\n",
      "Andhra Pradesh    1889513\n",
      "Name: Confirmed, dtype: int64\n",
      "\n",
      "Top 5 States by Deaths:\n",
      "State\n",
      "Maharashtra      121945\n",
      "Karnataka         35040\n",
      "Tamil Nadu        32619\n",
      "Delhi             24977\n",
      "Uttar Pradesh     22591\n",
      "Name: Deaths, dtype: int64\n",
      "\n",
      "Top 5 States by Case Fatality Rate:\n",
      "                          State  Total Cases  Total Deaths   CFR (%)\n",
      "24                     Nagaland        13039           404  3.098397\n",
      "0   Andaman and Nicobar Islands         2447            66  2.697180\n",
      "27                       Punjab       412800         10202  2.471415\n",
      "35                  Uttarakhand       243224          5624  2.312272\n",
      "9                           Goa       111663          2258  2.022156\n",
      "Generated frame for 2021-03-02\n",
      "Generated frame for 2021-03-09\n",
      "Generated frame for 2021-03-16\n",
      "Generated frame for 2021-03-23\n",
      "Generated frame for 2021-03-30\n",
      "Generated frame for 2021-04-06\n",
      "Generated frame for 2021-04-13\n",
      "Generated frame for 2021-04-20\n",
      "Generated frame for 2021-04-27\n",
      "Generated frame for 2021-05-04\n",
      "Generated frame for 2021-05-11\n",
      "Generated frame for 2021-05-18\n",
      "Generated frame for 2021-05-25\n",
      "Generated frame for 2021-06-01\n",
      "Generated frame for 2021-06-08\n",
      "Generated frame for 2021-06-15\n",
      "Generated frame for 2021-06-22\n",
      "Generated frame for 2021-06-29\n",
      "Created 18 animation frames.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydeck as pdk\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Load datasets\n",
    "covid_state_data = pd.read_csv('covid cases by state_Full Data_data (1).csv')\n",
    "covid_india = pd.read_csv('covid_19_india.csv')\n",
    "vaccine_data = pd.read_csv('COVID-19 India Statewise Vaccine Data.csv')\n",
    "covid2_new = pd.read_csv('Covid2_new.csv')\n",
    "testing_data = pd.read_csv('Statewise Testing Details_Full Data_data.csv')\n",
    "merged_data = pd.read_csv('merged_covid_vaccine_data.csv')\n",
    "\n",
    "# Fix date columns\n",
    "covid_state_data['Date'] = pd.to_datetime(covid_state_data['Date'])\n",
    "covid_india['Date'] = pd.to_datetime(covid_india['Date'])\n",
    "covid2_new['Date'] = pd.to_datetime(covid2_new['Date'])\n",
    "testing_data['Date'] = pd.to_datetime(testing_data['Date'])\n",
    "merged_data['Date'] = pd.to_datetime(merged_data['Date'])\n",
    "\n",
    "# Filter for second wave (March 2021 to July 2021)\n",
    "start_date = '2021-03-01'\n",
    "end_date = '2021-07-31'\n",
    "\n",
    "covid_state_wave2 = covid_state_data[(covid_state_data['Date'] >= start_date) & (covid_state_data['Date'] <= end_date)]\n",
    "covid_india_wave2 = covid_india[(covid_india['Date'] >= start_date) & (covid_india['Date'] <= end_date)]\n",
    "covid2_new_wave2 = covid2_new[(covid2_new['Date'] >= start_date) & (covid2_new['Date'] <= end_date)]\n",
    "merged_wave2 = merged_data[(merged_data['Date'] >= start_date) & (merged_data['Date'] <= end_date)]\n",
    "\n",
    "# State coordinates for mapping (approximate centroids)\n",
    "state_coordinates = {\n",
    "    'Maharashtra': [19.7515, 75.7139],\n",
    "    'Kerala': [10.8505, 76.2711],\n",
    "    'Karnataka': [15.3173, 75.7139],\n",
    "    'Tamil Nadu': [11.1271, 78.6569],\n",
    "    'Andhra Pradesh': [15.9129, 79.7400],\n",
    "    'Uttar Pradesh': [26.8467, 80.9462],\n",
    "    'Delhi': [28.7041, 77.1025],\n",
    "    'West Bengal': [22.9868, 87.8550],\n",
    "    'Rajasthan': [27.0238, 74.2179],\n",
    "    'Gujarat': [22.2587, 71.1924],\n",
    "    'Madhya Pradesh': [22.9734, 78.6569],\n",
    "    'Haryana': [29.0588, 76.0856],\n",
    "    'Bihar': [25.0961, 85.3131],\n",
    "    'Telangana': [18.1124, 79.0193],\n",
    "    'Odisha': [20.9517, 85.0985],\n",
    "    'Punjab': [31.1471, 75.3412],\n",
    "    'Assam': [26.2006, 92.9376],\n",
    "    'Jharkhand': [23.6102, 85.2799],\n",
    "    'Uttarakhand': [30.0668, 79.0193],\n",
    "    'Chhattisgarh': [21.2787, 81.8661],\n",
    "    'Himachal Pradesh': [31.1048, 77.1734],\n",
    "    'Goa': [15.2993, 74.1240],\n",
    "    'Jammu and Kashmir': [33.7782, 76.5762],\n",
    "    'Puducherry': [11.9416, 79.8083],\n",
    "    'Tripura': [23.9408, 91.9882],\n",
    "    'Chandigarh': [30.7333, 76.7794],\n",
    "    'Manipur': [24.6637, 93.9063],\n",
    "    'Meghalaya': [25.4670, 91.3662],\n",
    "    'Nagaland': [26.1584, 94.5624],\n",
    "    'Arunachal Pradesh': [28.2180, 94.7278],\n",
    "    'Mizoram': [23.1645, 92.9376],\n",
    "    'Sikkim': [27.5330, 88.5122],\n",
    "    'Dadra and Nagar Haveli': [20.1809, 73.0169],\n",
    "    'Daman and Diu': [20.4283, 72.8397],\n",
    "    'Andaman and Nicobar Islands': [11.7401, 92.6586],\n",
    "    'Lakshadweep': [10.5667, 72.6417],\n",
    "    'Ladakh': [34.1526, 77.5770]\n",
    "}\n",
    "\n",
    "# Function to prepare data for PyDeck\n",
    "def prepare_data_for_pydeck(df, date_snapshot):\n",
    "    df_snapshot = df[df['Date'] == date_snapshot].copy()\n",
    "    \n",
    "    # Create DataFrame with state coordinates\n",
    "    data_with_coords = []\n",
    "    \n",
    "    for index, row in df_snapshot.iterrows():\n",
    "        state = row['State']\n",
    "        # Clean up state names to match our coordinates dictionary\n",
    "        if state in state_coordinates:\n",
    "            lat, lon = state_coordinates[state]\n",
    "            new_row = row.to_dict()\n",
    "            new_row['latitude'] = lat\n",
    "            new_row['longitude'] = lon\n",
    "            data_with_coords.append(new_row)\n",
    "    \n",
    "    return pd.DataFrame(data_with_coords)\n",
    "\n",
    "# Create aggregated state data with peak metrics during second wave\n",
    "peak_data = []\n",
    "\n",
    "for state in covid2_new_wave2['State'].unique():\n",
    "    state_data = covid2_new_wave2[covid2_new_wave2['State'] == state]\n",
    "    \n",
    "    # Find peak metrics\n",
    "    peak_cases = state_data['Confirmed'].max()\n",
    "    peak_new_cases = state_data['New Cases'].max()\n",
    "    peak_deaths = state_data['Deaths'].max()\n",
    "    peak_date = state_data.loc[state_data['New Cases'].idxmax(), 'Date']\n",
    "    \n",
    "    # Calc total metrics for the wave\n",
    "    total_cases = state_data['New Cases'].sum()\n",
    "    total_deaths = state_data['Deaths'].max() - state_data['Deaths'].min()\n",
    "    \n",
    "    # Get coordinates\n",
    "    if state in state_coordinates:\n",
    "        lat, lon = state_coordinates[state]\n",
    "        \n",
    "        peak_data.append({\n",
    "            'State': state,\n",
    "            'Peak_Daily_Cases': peak_new_cases,\n",
    "            'Peak_Date': peak_date,\n",
    "            'Total_Wave2_Cases': total_cases,\n",
    "            'Total_Wave2_Deaths': total_deaths,\n",
    "            'CFR': (total_deaths / total_cases * 100) if total_cases > 0 else 0,\n",
    "            'latitude': lat,\n",
    "            'longitude': lon\n",
    "        })\n",
    "\n",
    "peak_df = pd.DataFrame(peak_data)\n",
    "\n",
    "# Create a column view for the hover tooltip\n",
    "def create_description(row):\n",
    "    return f\"{row['State']}<br>Peak Daily Cases: {int(row['Peak_Daily_Cases']):,}<br>Total Wave 2 Cases: {int(row['Total_Wave2_Cases']):,}<br>CFR: {row['CFR']:.2f}%\"\n",
    "\n",
    "peak_df['description'] = peak_df.apply(create_description, axis=1)\n",
    "\n",
    "# 1. PEAK COVID CASES MAP VISUALIZATION\n",
    "def create_peak_cases_map(peak_df):\n",
    "    # Normalize the radius values\n",
    "    peak_df['radius'] = peak_df['Peak_Daily_Cases'] / peak_df['Peak_Daily_Cases'].max() * 100000\n",
    "    \n",
    "    # Create the layer\n",
    "    layer = pdk.Layer(\n",
    "        \"ScatterplotLayer\",\n",
    "        peak_df,\n",
    "        get_position=[\"longitude\", \"latitude\"],\n",
    "        get_radius=\"radius\",\n",
    "        get_fill_color=[255, 0, 0, 140],  # Red with alpha\n",
    "        pickable=True,\n",
    "        opacity=0.8,\n",
    "        stroked=True,\n",
    "        filled=True,\n",
    "    )\n",
    "    \n",
    "    # Set the view state\n",
    "    view_state = pdk.ViewState(\n",
    "        longitude=78.9629, \n",
    "        latitude=22.5937,  # Center of India\n",
    "        zoom=4,\n",
    "        min_zoom=3,\n",
    "        max_zoom=10,\n",
    "        pitch=0,\n",
    "        bearing=0\n",
    "    )\n",
    "    \n",
    "    # Create the tooltip\n",
    "    tooltip = {\n",
    "        \"html\": \"<b>{State}</b><br>Peak Daily Cases: {Peak_Daily_Cases}<br>On: {Peak_Date}<br>Total Wave2 Cases: {Total_Wave2_Cases}<br>CFR: {CFR}%\",\n",
    "        \"style\": {\"backgroundColor\": \"steelblue\", \"color\": \"white\"}\n",
    "    }\n",
    "    \n",
    "    # Create the deck\n",
    "    deck = pdk.Deck(\n",
    "        layers=[layer],\n",
    "        initial_view_state=view_state,\n",
    "        tooltip=tooltip,\n",
    "        map_style=\"mapbox://styles/mapbox/light-v9\"\n",
    "    )\n",
    "    \n",
    "    return deck\n",
    "\n",
    "# 2. CHOROPLETH MAP FOR CFR (CASE FATALITY RATE)\n",
    "# def create_cfr_map(peak_df):\n",
    "#     # Define a color scale for CFR\n",
    "#     peak_df['color_r'] = (peak_df['CFR'] / peak_df['CFR'].max() * 255).astype(int)\n",
    "    \n",
    "#     layer = pdk.Layer(\n",
    "#         \"ScatterplotLayer\",\n",
    "#         peak_df,\n",
    "#         get_position=[\"longitude\", \"latitude\"],\n",
    "#         get_radius=50000,  # Fixed radius\n",
    "#         get_fill_color=[\"color_r\", 10, 10, 200],  # Red scale based on CFR\n",
    "#         pickable=True,\n",
    "#         opacity=0.8,\n",
    "#         stroked=True,\n",
    "#         filled=True,\n",
    "#     )\n",
    "    \n",
    "#     view_state = pdk.ViewState(\n",
    "#         longitude=78.9629, \n",
    "#         latitude=22.5937,  # Center of India\n",
    "#         zoom=4,\n",
    "#         min_zoom=3,\n",
    "#         max_zoom=10,\n",
    "#         pitch=0,\n",
    "#         bearing=0\n",
    "#     )\n",
    "    \n",
    "#     tooltip = {\n",
    "#         \"html\": \"<b>{State}</b><br>Case Fatality Rate: {CFR:.2f}%<br>Total Deaths: {Total_Wave2_Deaths}\",\n",
    "#         \"style\": {\"backgroundColor\": \"darkred\", \"color\": \"white\"}\n",
    "#     }\n",
    "    \n",
    "#     deck = pdk.Deck(\n",
    "#         layers=[layer],\n",
    "#         initial_view_state=view_state,\n",
    "#         tooltip=tooltip,\n",
    "#         map_style=\"mapbox://styles/mapbox/light-v9\"\n",
    "#     )\n",
    "    \n",
    "#     return deck\n",
    "\n",
    "# 3. TIME SERIES VISUALIZATION FOR TOP STATES\n",
    "def prepare_time_series_data(covid2_new_wave2):\n",
    "    # Get top 5 states by total cases\n",
    "    top_states = covid2_new_wave2.groupby('State')['Confirmed'].max().nlargest(5).index.tolist()\n",
    "    \n",
    "    # Filter for these states\n",
    "    top_states_data = covid2_new_wave2[covid2_new_wave2['State'].isin(top_states)]\n",
    "    \n",
    "    # Create a time series dataset\n",
    "    time_series = []\n",
    "    \n",
    "    for state in top_states:\n",
    "        state_data = top_states_data[top_states_data['State'] == state].sort_values('Date')\n",
    "        \n",
    "        for _, row in state_data.iterrows():\n",
    "            time_series.append({\n",
    "                'State': state,\n",
    "                'Date': row['Date'],\n",
    "                'New_Cases': row['New Cases'],\n",
    "                'Confirmed': row['Confirmed'],\n",
    "                'Deaths': row['Deaths'],\n",
    "                'latitude': state_coordinates[state][0],\n",
    "                'longitude': state_coordinates[state][1]\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(time_series)\n",
    "\n",
    "# 4. VACCINATION ANALYSIS\n",
    "def analyze_vaccination_data(merged_wave2):\n",
    "    # Group by state and date, then calculate stats\n",
    "    vax_data = merged_wave2.groupby(['State', 'Date']).agg({\n",
    "        'Total Doses Administered': 'max',\n",
    "        'First Dose Administered': 'max',\n",
    "        'Second Dose Administered': 'max',\n",
    "        'Male (Doses Administered)': 'max',\n",
    "        'Female (Doses Administered)': 'max'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Get the last record for each state to show final vaccination status\n",
    "    final_vax = vax_data.sort_values('Date').groupby('State').last().reset_index()\n",
    "    \n",
    "    # Add coordinates\n",
    "    final_vax_with_coords = []\n",
    "    for index, row in final_vax.iterrows():\n",
    "        state = row['State']\n",
    "        if state in state_coordinates:\n",
    "            lat, lon = state_coordinates[state]\n",
    "            new_row = row.to_dict()\n",
    "            new_row['latitude'] = lat\n",
    "            new_row['longitude'] = lon\n",
    "            final_vax_with_coords.append(new_row)\n",
    "    \n",
    "    return pd.DataFrame(final_vax_with_coords)\n",
    "\n",
    "# Create the vaccination visualization\n",
    "def create_vaccination_map(vax_data):\n",
    "    # Normalize for visualization\n",
    "    max_doses = vax_data['Total Doses Administered'].max()\n",
    "    vax_data['radius'] = vax_data['Total Doses Administered'] / max_doses * 100000\n",
    "    \n",
    "    layer = pdk.Layer(\n",
    "        \"ScatterplotLayer\",\n",
    "        vax_data,\n",
    "        get_position=[\"longitude\", \"latitude\"],\n",
    "        get_radius=\"radius\",\n",
    "        get_fill_color=[0, 128, 255, 140],  # Blue with alpha\n",
    "        pickable=True,\n",
    "        opacity=0.8,\n",
    "        stroked=True,\n",
    "        filled=True,\n",
    "    )\n",
    "    \n",
    "    view_state = pdk.ViewState(\n",
    "        longitude=78.9629, \n",
    "        latitude=22.5937,  # Center of India\n",
    "        zoom=4,\n",
    "        min_zoom=3,\n",
    "        max_zoom=10,\n",
    "        pitch=0,\n",
    "        bearing=0\n",
    "    )\n",
    "    \n",
    "    tooltip = {\n",
    "        \"html\": \"<b>{State}</b><br>Total Doses: {Total Doses Administered:,.0f}<br>First Doses: {First Dose Administered:,.0f}<br>Second Doses: {Second Dose Administered:,.0f}\",\n",
    "        \"style\": {\"backgroundColor\": \"royalblue\", \"color\": \"white\"}\n",
    "    }\n",
    "    \n",
    "    deck = pdk.Deck(\n",
    "        layers=[layer],\n",
    "        initial_view_state=view_state,\n",
    "        tooltip=tooltip,\n",
    "        map_style=\"mapbox://styles/mapbox/light-v9\"\n",
    "    )\n",
    "    \n",
    "    return deck\n",
    "\n",
    "# 5. VACCINATION vs CASE CORRELATION\n",
    "def vaccination_vs_cases(merged_wave2):\n",
    "    # Group by state to get final statistics\n",
    "    state_stats = merged_wave2.groupby('State').agg({\n",
    "        'Total Doses Administered': 'max',\n",
    "        'Confirmed': 'max',\n",
    "        'Deaths': 'max'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Add coordinates\n",
    "    state_stats_with_coords = []\n",
    "    for index, row in state_stats.iterrows():\n",
    "        state = row['State']\n",
    "        if state in state_coordinates:\n",
    "            lat, lon = state_coordinates[state]\n",
    "            new_row = row.to_dict()\n",
    "            new_row['latitude'] = lat\n",
    "            new_row['longitude'] = lon\n",
    "            \n",
    "            # Calculate cases per 100k vaccines\n",
    "            if row['Total Doses Administered'] > 0:\n",
    "                new_row['Cases_per_100k_Vaccines'] = (row['Confirmed'] / row['Total Doses Administered']) * 100000\n",
    "            else:\n",
    "                new_row['Cases_per_100k_Vaccines'] = 0\n",
    "                \n",
    "            state_stats_with_coords.append(new_row)\n",
    "    \n",
    "    return pd.DataFrame(state_stats_with_coords)\n",
    "\n",
    "# IMPLEMENTATION - COMBINE ALL VISUALIZATIONS IN A DASHBOARD\n",
    "\n",
    "# Prepare all datasets\n",
    "peak_cases_data = peak_df\n",
    "# cfr_data = peak_df\n",
    "time_series_data = prepare_time_series_data(covid2_new_wave2)\n",
    "vaccination_data = analyze_vaccination_data(merged_wave2)\n",
    "vax_vs_cases = vaccination_vs_cases(merged_wave2)\n",
    "\n",
    "# CREATE THE MAIN FUNCTION TO GENERATE THE DASHBOARD\n",
    "def generate_covid_dashboard():\n",
    "    # Create all the visualization decks\n",
    "    peak_cases_deck = create_peak_cases_map(peak_cases_data)\n",
    "    # cfr_deck = create_cfr_map(cfr_data)\n",
    "    vaccination_deck = create_vaccination_map(vaccination_data)\n",
    "    \n",
    "    # For demonstration in a notebook environment\n",
    "    # Note: For a deployed application, you would use appropriate layout frameworks like Dash or Streamlit\n",
    "    \n",
    "    print(\"COVID-19 Second Wave Dashboard (March-July 2021)\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"\\n1. PEAK COVID CASES MAP VISUALIZATION\")\n",
    "    peak_cases_deck.to_html(\"peak_cases_map.html\")\n",
    "    \n",
    "    # print(\"\\n2. CASE FATALITY RATE (CFR) MAP\")\n",
    "    # cfr_deck.to_html(\"cfr_map.html\")\n",
    "    \n",
    "    print(\"\\n2. VACCINATION PROGRESS MAP\")\n",
    "    vaccination_deck.to_html(\"vaccination_map.html\")\n",
    "    \n",
    "    # Create additional analytics as HTML files for complete dashboard\n",
    "    # This section would use matplotlib, seaborn or plotly to generate additional charts\n",
    "    \n",
    "    # Return the main deck for display\n",
    "    return peak_cases_deck\n",
    "\n",
    "# Call the function to generate the dashboard\n",
    "covid_dashboard = generate_covid_dashboard()\n",
    "\n",
    "# Function to animate the progression of cases over time\n",
    "def create_time_animation(covid2_new_wave2):\n",
    "    # Get unique dates to animate through\n",
    "    dates = sorted(covid2_new_wave2['Date'].unique())\n",
    "    \n",
    "    # Sample every 7 days to make animation manageable\n",
    "    sampled_dates = dates[::7]\n",
    "    \n",
    "    animation_frames = []\n",
    "    \n",
    "    for date in sampled_dates:\n",
    "        date_str = pd.to_datetime(date).strftime('%Y-%m-%d')\n",
    "        day_data = prepare_data_for_pydeck(covid2_new_wave2, date)\n",
    "        \n",
    "        if not day_data.empty:\n",
    "            # Normalize radius based on confirmed cases\n",
    "            max_cases = day_data['Confirmed'].max()\n",
    "            if max_cases > 0:\n",
    "                day_data['radius'] = day_data['Confirmed'] / max_cases * 100000\n",
    "            else:\n",
    "                day_data['radius'] = 10000  # Default radius if no cases\n",
    "                \n",
    "            layer = pdk.Layer(\n",
    "                \"ScatterplotLayer\",\n",
    "                day_data,\n",
    "                get_position=[\"longitude\", \"latitude\"],\n",
    "                get_radius=\"radius\",\n",
    "                get_fill_color=[255, 0, 0, 140],\n",
    "                pickable=True,\n",
    "                opacity=0.8,\n",
    "                stroked=True,\n",
    "                filled=True,\n",
    "            )\n",
    "            \n",
    "            view_state = pdk.ViewState(\n",
    "                longitude=78.9629, \n",
    "                latitude=22.5937,\n",
    "                zoom=4,\n",
    "                min_zoom=3,\n",
    "                max_zoom=10,\n",
    "                pitch=0,\n",
    "                bearing=0\n",
    "            )\n",
    "            \n",
    "            tooltip = {\n",
    "                \"html\": \"<b>{State}</b><br>Date: {Date}<br>Confirmed: {Confirmed}<br>Deaths: {Deaths}\",\n",
    "                \"style\": {\"backgroundColor\": \"steelblue\", \"color\": \"white\"}\n",
    "            }\n",
    "            \n",
    "            deck = pdk.Deck(\n",
    "                layers=[layer],\n",
    "                initial_view_state=view_state,\n",
    "                tooltip=tooltip,\n",
    "                map_style=\"mapbox://styles/mapbox/light-v9\"\n",
    "            )\n",
    "            \n",
    "            # Save this frame\n",
    "            html_path = f\"animation_frame_{date_str}.html\"\n",
    "            deck.to_html(html_path)\n",
    "            animation_frames.append(html_path)\n",
    "            \n",
    "            print(f\"Generated frame for {date_str}\")\n",
    "    \n",
    "    print(f\"Created {len(animation_frames)} animation frames.\")\n",
    "    return animation_frames\n",
    "\n",
    "# Additional function for detailed analysis\n",
    "def generate_detailed_analysis():\n",
    "    # 1. Top 5 states with highest cases\n",
    "    top_case_states = covid2_new_wave2.groupby('State')['Confirmed'].max().nlargest(5)\n",
    "    \n",
    "    # 2. Top 5 states with highest deaths\n",
    "    top_death_states = covid2_new_wave2.groupby('State')['Deaths'].max().nlargest(5)\n",
    "    \n",
    "    # 3. Calculate case fatality rates for all states\n",
    "    cfr_by_state = []\n",
    "    \n",
    "    for state in covid2_new_wave2['State'].unique():\n",
    "        state_data = covid2_new_wave2[covid2_new_wave2['State'] == state]\n",
    "        first_record = state_data.iloc[0]\n",
    "        last_record = state_data.iloc[-1]\n",
    "        \n",
    "        total_cases = last_record['Confirmed'] - first_record['Confirmed']\n",
    "        total_deaths = last_record['Deaths'] - first_record['Deaths']\n",
    "        \n",
    "        cfr = (total_deaths / total_cases * 100) if total_cases > 0 else 0\n",
    "        \n",
    "        cfr_by_state.append({\n",
    "            'State': state,\n",
    "            'Total Cases': total_cases,\n",
    "            'Total Deaths': total_deaths,\n",
    "            'CFR (%)': cfr\n",
    "        })\n",
    "    \n",
    "    cfr_df = pd.DataFrame(cfr_by_state)\n",
    "    top_cfr_states = cfr_df.sort_values('CFR (%)', ascending=False).head(5)\n",
    "    \n",
    "    # 4. Vaccination progress correlation with cases (if data available)\n",
    "    # This would be implemented if the merged_wave2 dataset has the necessary data\n",
    "    \n",
    "    # Print the analysis results\n",
    "    print(\"\\nDETAILED ANALYSIS OF COVID-19 SECOND WAVE (MARCH-JULY 2021)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\nTop 5 States by Confirmed Cases:\")\n",
    "    print(top_case_states)\n",
    "    \n",
    "    print(\"\\nTop 5 States by Deaths:\")\n",
    "    print(top_death_states)\n",
    "    \n",
    "    print(\"\\nTop 5 States by Case Fatality Rate:\")\n",
    "    print(top_cfr_states)\n",
    "    \n",
    "    return {\n",
    "        'top_cases': top_case_states,\n",
    "        'top_deaths': top_death_states,\n",
    "        'top_cfr': top_cfr_states\n",
    "    }\n",
    "\n",
    "# Run the dashboard and analysis\n",
    "covid_dashboard = generate_covid_dashboard()\n",
    "detailed_analysis = generate_detailed_analysis()\n",
    "animation_frames = create_time_animation(covid2_new_wave2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c870ca0-6673-4d4d-8f25-209f7a10fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydeck as pdk\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the merged dataset that contains both COVID cases and vaccination data\n",
    "merged_data = pd.read_csv('merged_covid_vaccine_data.csv')\n",
    "\n",
    "# Convert date column to datetime\n",
    "merged_data['Date'] = pd.to_datetime(merged_data['Date'])\n",
    "\n",
    "# Filter for second wave period (March 2021 to July 2021)\n",
    "start_date = '2021-03-01'\n",
    "end_date = '2021-07-31'\n",
    "wave2_data = merged_data[(merged_data['Date'] >= start_date) & (merged_data['Date'] <= end_date)]\n",
    "\n",
    "# Calculate rolling averages for smoother trends\n",
    "def prepare_state_trends(state_data):\n",
    "    # Sort by date\n",
    "    state_data = state_data.sort_values('Date')\n",
    "    \n",
    "    # Calculate 7-day rolling averages\n",
    "    state_data['Cases_7day_avg'] = state_data['New Cases'].rolling(7).mean()\n",
    "    \n",
    "    # Calculate daily vaccination rate (first difference of cumulative doses)\n",
    "    state_data['Daily_Doses'] = state_data['Total Doses Administered'].diff()\n",
    "    state_data['Doses_7day_avg'] = state_data['Daily_Doses'].rolling(7).mean()\n",
    "    \n",
    "    return state_data\n",
    "\n",
    "# Function to create visualization for a specific state\n",
    "def create_state_vaccination_impact(state_name):\n",
    "    state_data = wave2_data[wave2_data['State'] == state_name].copy()\n",
    "    \n",
    "    if len(state_data) < 10:  # Skip if insufficient data\n",
    "        return None\n",
    "    \n",
    "    state_data = prepare_state_trends(state_data)\n",
    "    \n",
    "    # Create a dual-axis plot\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    \n",
    "    # Add new cases trend\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=state_data['Date'], \n",
    "            y=state_data['Cases_7day_avg'],\n",
    "            name=\"New Cases (7-day avg)\",\n",
    "            line=dict(color='red', width=2)\n",
    "        ),\n",
    "        secondary_y=False\n",
    "    )\n",
    "    \n",
    "    # Add vaccination trend\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=state_data['Date'], \n",
    "            y=state_data['Doses_7day_avg'],\n",
    "            name=\"Daily Vaccinations (7-day avg)\",\n",
    "            line=dict(color='blue', width=2)\n",
    "        ),\n",
    "        secondary_y=True\n",
    "    )\n",
    "    \n",
    "    # Add titles and labels\n",
    "    fig.update_layout(\n",
    "        title_text=f\"COVID-19 Cases vs. Vaccination Rate: {state_name}\",\n",
    "        xaxis_title=\"Date\",\n",
    "        legend=dict(y=0.99, x=0.01, orientation='h'),\n",
    "        template='plotly_white',\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"New Cases (7-day avg)\", secondary_y=False)\n",
    "    fig.update_yaxes(title_text=\"Daily Vaccinations (7-day avg)\", secondary_y=True)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Function to analyze vaccination impact across all states\n",
    "def analyze_vaccination_impact():\n",
    "    # Get list of top 10 states by total cases\n",
    "    case_totals = wave2_data.groupby('State')['Confirmed'].max().nlargest(10)\n",
    "    top_states = case_totals.index.tolist()\n",
    "    \n",
    "    # Calculate metrics to measure vaccination impact\n",
    "    impact_metrics = []\n",
    "    \n",
    "    for state in top_states:\n",
    "        state_data = wave2_data[wave2_data['State'] == state].copy()\n",
    "        \n",
    "        if len(state_data) < 30:  # Skip if insufficient data\n",
    "            continue\n",
    "            \n",
    "        state_data = state_data.sort_values('Date')\n",
    "        \n",
    "        # Get vaccination and case data\n",
    "        first_record = state_data.iloc[0]\n",
    "        peak_record = state_data.loc[state_data['New Cases'].idxmax()]\n",
    "        last_record = state_data.iloc[-1]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        pre_vax_cases = first_record['Confirmed']\n",
    "        peak_cases = peak_record['Confirmed']\n",
    "        end_cases = last_record['Confirmed']\n",
    "        \n",
    "        start_vax = first_record['Total Doses Administered'] if not pd.isna(first_record['Total Doses Administered']) else 0\n",
    "        peak_vax = peak_record['Total Doses Administered'] if not pd.isna(peak_record['Total Doses Administered']) else 0\n",
    "        end_vax = last_record['Total Doses Administered'] if not pd.isna(last_record['Total Doses Administered']) else 0\n",
    "        \n",
    "        # Calculate the case decline rate after peak\n",
    "        days_after_peak = (last_record['Date'] - peak_record['Date']).days\n",
    "        if days_after_peak > 0:\n",
    "            case_decline_rate = (peak_cases - end_cases) / days_after_peak\n",
    "        else:\n",
    "            case_decline_rate = 0\n",
    "            \n",
    "        # Calculate vaccination rate\n",
    "        total_days = (last_record['Date'] - first_record['Date']).days\n",
    "        if total_days > 0:\n",
    "            vax_rate = (end_vax - start_vax) / total_days\n",
    "        else:\n",
    "            vax_rate = 0\n",
    "        \n",
    "        impact_metrics.append({\n",
    "            'State': state,\n",
    "            'Case_Growth_to_Peak': peak_cases - pre_vax_cases,\n",
    "            'Case_Decline_After_Peak': end_cases - peak_cases,\n",
    "            'Daily_Case_Decline_Rate': case_decline_rate,\n",
    "            'Daily_Vaccination_Rate': vax_rate,\n",
    "            'Total_Vaccinations': end_vax,\n",
    "            'Peak_Date': peak_record['Date'],\n",
    "            'Peak_Cases': peak_record['New Cases']\n",
    "        })\n",
    "    \n",
    "    impact_df = pd.DataFrame(impact_metrics)\n",
    "    \n",
    "    # Create visualization of relationship between vaccination rate and case decline\n",
    "    fig = px.scatter(\n",
    "        impact_df, \n",
    "        x='Daily_Vaccination_Rate', \n",
    "        y='Daily_Case_Decline_Rate',\n",
    "        size='Total_Vaccinations',\n",
    "        color='Peak_Cases',\n",
    "        hover_name='State',\n",
    "        text='State',\n",
    "        color_continuous_scale='Viridis',\n",
    "        title='Relationship Between Vaccination Rate and COVID-19 Case Decline Rate',\n",
    "        labels={\n",
    "            'Daily_Vaccination_Rate': 'Daily Vaccination Rate (doses/day)',\n",
    "            'Daily_Case_Decline_Rate': 'Daily Case Decline Rate (cases/day)',\n",
    "            'Total_Vaccinations': 'Total Vaccinations',\n",
    "            'Peak_Cases': 'Peak Daily Cases'\n",
    "        },\n",
    "        size_max=50\n",
    "    )\n",
    "    \n",
    "    fig.update_traces(textposition='top center')\n",
    "    fig.update_layout(height=700, template='plotly_white')\n",
    "    \n",
    "    return fig, impact_df\n",
    "\n",
    "# Function to create vaccination distribution analysis\n",
    "def analyze_vaccination_distribution():\n",
    "    # Filter the last available record for each state to get final vaccination numbers\n",
    "    latest_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6383444d-4376-4305-b0cd-0b596a8b165b",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Address 'http://127.0.0.1:8050' already in use.\n    Try passing a different port to run.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 732\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    731\u001b[0m     app \u001b[38;5;241m=\u001b[39m create_dashboard()\n\u001b[1;32m--> 732\u001b[0m     app\u001b[38;5;241m.\u001b[39mrun(debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDashboard is running. Open http://127.0.0.1:8050/ in your web browser to view it.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Users\\me\\anaconda3\\envs\\sat_env\\Lib\\site-packages\\dash\\dash.py:2257\u001b[0m, in \u001b[0;36mDash.run\u001b[1;34m(self, host, port, proxy, debug, jupyter_mode, jupyter_width, jupyter_height, jupyter_server_url, dev_tools_ui, dev_tools_props_check, dev_tools_serve_dev_bundles, dev_tools_hot_reload, dev_tools_hot_reload_interval, dev_tools_hot_reload_watch_interval, dev_tools_hot_reload_max_retry, dev_tools_silence_routes_logging, dev_tools_disable_version_check, dev_tools_prune_errors, **flask_run_options)\u001b[0m\n\u001b[0;32m   2254\u001b[0m             extra_files\u001b[38;5;241m.\u001b[39mappend(path)\n\u001b[0;32m   2256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m jupyter_dash\u001b[38;5;241m.\u001b[39mactive:\n\u001b[1;32m-> 2257\u001b[0m     jupyter_dash\u001b[38;5;241m.\u001b[39mrun_app(\n\u001b[0;32m   2258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2259\u001b[0m         mode\u001b[38;5;241m=\u001b[39mjupyter_mode,\n\u001b[0;32m   2260\u001b[0m         width\u001b[38;5;241m=\u001b[39mjupyter_width,\n\u001b[0;32m   2261\u001b[0m         height\u001b[38;5;241m=\u001b[39mjupyter_height,\n\u001b[0;32m   2262\u001b[0m         host\u001b[38;5;241m=\u001b[39mhost,\n\u001b[0;32m   2263\u001b[0m         port\u001b[38;5;241m=\u001b[39mport,\n\u001b[0;32m   2264\u001b[0m         server_url\u001b[38;5;241m=\u001b[39mjupyter_server_url,\n\u001b[0;32m   2265\u001b[0m     )\n\u001b[0;32m   2266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver\u001b[38;5;241m.\u001b[39mrun(host\u001b[38;5;241m=\u001b[39mhost, port\u001b[38;5;241m=\u001b[39mport, debug\u001b[38;5;241m=\u001b[39mdebug, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflask_run_options)\n",
      "File \u001b[1;32mD:\\Users\\me\\anaconda3\\envs\\sat_env\\Lib\\site-packages\\dash\\_jupyter.py:405\u001b[0m, in \u001b[0;36mJupyterDash.run_app\u001b[1;34m(self, app, mode, width, height, host, port, server_url)\u001b[0m\n\u001b[0;32m    403\u001b[0m     display(HTML(msg))\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 405\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_error\n",
      "File \u001b[1;32mD:\\Users\\me\\anaconda3\\envs\\sat_env\\Lib\\site-packages\\dash\\_jupyter.py:392\u001b[0m, in \u001b[0;36mJupyterDash.run_app\u001b[1;34m(self, app, mode, width, height, host, port, server_url)\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 392\u001b[0m     wait_for_app()\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_colab:\n\u001b[0;32m    395\u001b[0m         JupyterDash\u001b[38;5;241m.\u001b[39m_display_in_colab(dashboard_url, port, mode, width, height)\n",
      "File \u001b[1;32mD:\\Users\\me\\anaconda3\\envs\\sat_env\\Lib\\site-packages\\retrying.py:56\u001b[0m, in \u001b[0;36mretry.<locals>.wrap.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;129m@six\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Retrying(\u001b[38;5;241m*\u001b[39mdargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdkw)\u001b[38;5;241m.\u001b[39mcall(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mD:\\Users\\me\\anaconda3\\envs\\sat_env\\Lib\\site-packages\\retrying.py:266\u001b[0m, in \u001b[0;36mRetrying.call\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop(attempt_number, delay_since_first_attempt_ms):\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_exception \u001b[38;5;129;01mand\u001b[39;00m attempt\u001b[38;5;241m.\u001b[39mhas_exception:\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;66;03m# get() on an attempt with an exception should cause it to be raised, but raise just in case\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m attempt\u001b[38;5;241m.\u001b[39mget()\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RetryError(attempt)\n",
      "File \u001b[1;32mD:\\Users\\me\\anaconda3\\envs\\sat_env\\Lib\\site-packages\\retrying.py:301\u001b[0m, in \u001b[0;36mAttempt.get\u001b[1;34m(self, wrap_exception)\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RetryError(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 301\u001b[0m         six\u001b[38;5;241m.\u001b[39mreraise(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32mD:\\Users\\me\\anaconda3\\envs\\sat_env\\Lib\\site-packages\\six.py:719\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[0;32m    718\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 719\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[0;32m    720\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    721\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Users\\me\\anaconda3\\envs\\sat_env\\Lib\\site-packages\\retrying.py:251\u001b[0m, in \u001b[0;36mRetrying.call\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_attempts(attempt_number)\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 251\u001b[0m     attempt \u001b[38;5;241m=\u001b[39m Attempt(fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), attempt_number, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     tb \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[1;32mD:\\Users\\me\\anaconda3\\envs\\sat_env\\Lib\\site-packages\\dash\\_jupyter.py:383\u001b[0m, in \u001b[0;36mJupyterDash.run_app.<locals>.wait_for_app\u001b[1;34m()\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlive\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    382\u001b[0m         url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mport\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 383\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m    384\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAddress \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already in use.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    385\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Try passing a different port to run.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    386\u001b[0m         )\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mConnectionError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    388\u001b[0m     _get_error()\n",
      "\u001b[1;31mOSError\u001b[0m: Address 'http://127.0.0.1:8050' already in use.\n    Try passing a different port to run."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydeck as pdk\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "import dash_bootstrap_components as dbc\n",
    "import json\n",
    "import base64\n",
    "\n",
    "# Load datasets\n",
    "def load_datasets():\n",
    "    covid_state_data = pd.read_csv('covid cases by state_Full Data_data (1).csv')\n",
    "    covid_india = pd.read_csv('covid_19_india.csv')\n",
    "    vaccine_data = pd.read_csv('COVID-19 India Statewise Vaccine Data.csv')\n",
    "    covid2_new = pd.read_csv('Covid2_new.csv')\n",
    "    testing_data = pd.read_csv('Statewise Testing Details_Full Data_data.csv')\n",
    "    merged_data = pd.read_csv('merged_covid_vaccine_data.csv')\n",
    "    age_group_data = pd.read_csv('AgeGroupDetails.csv')\n",
    "    # gender_data = pd.read_csv('Gender without missing values_Full Data_data.csv')\n",
    "    \n",
    "    # Fix date columns\n",
    "    covid_state_data['Date'] = pd.to_datetime(covid_state_data['Date'])\n",
    "    covid_india['Date'] = pd.to_datetime(covid_india['Date'])\n",
    "    covid2_new['Date'] = pd.to_datetime(covid2_new['Date'])\n",
    "    testing_data['Date'] = pd.to_datetime(testing_data['Date'])\n",
    "    merged_data['Date'] = pd.to_datetime(merged_data['Date'])\n",
    "    # gender_data['Diagnosed Date'] = pd.to_datetime(gender_data['Diagnosed Date'])\n",
    "    \n",
    "    return {\n",
    "        'covid_state': covid_state_data,\n",
    "        'covid_india': covid_india,\n",
    "        'vaccine': vaccine_data,\n",
    "        'covid2': covid2_new,\n",
    "        'testing': testing_data,\n",
    "        'merged': merged_data,\n",
    "        'age_group': age_group_data,\n",
    "        # 'gender': gender_data\n",
    "    }\n",
    "\n",
    "# Filter for second wave period (March 2021 to July 2021)\n",
    "def filter_wave2_data(datasets):\n",
    "    start_date = '2021-03-01'\n",
    "    end_date = '2021-07-31'\n",
    "    \n",
    "    wave2_datasets = {}\n",
    "    \n",
    "    for key, df in datasets.items():\n",
    "        if 'Date' in df.columns:\n",
    "            wave2_datasets[key] = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "        # elif key == 'gender':\n",
    "        #     wave2_datasets[key] = df[(df['Diagnosed Date'] >= start_date) & (df['Diagnosed Date'] <= end_date)]\n",
    "        else:\n",
    "            wave2_datasets[key] = df\n",
    "    \n",
    "    return wave2_datasets\n",
    "\n",
    "# State coordinates for mapping (approximate centroids)\n",
    "state_coordinates = {\n",
    "    'Maharashtra': [19.7515, 75.7139],\n",
    "    'Kerala': [10.8505, 76.2711],\n",
    "    'Karnataka': [15.3173, 75.7139],\n",
    "    'Tamil Nadu': [11.1271, 78.6569],\n",
    "    'Andhra Pradesh': [15.9129, 79.7400],\n",
    "    'Uttar Pradesh': [26.8467, 80.9462],\n",
    "    'Delhi': [28.7041, 77.1025],\n",
    "    'West Bengal': [22.9868, 87.8550],\n",
    "    'Rajasthan': [27.0238, 74.2179],\n",
    "    'Gujarat': [22.2587, 71.1924],\n",
    "    'Madhya Pradesh': [22.9734, 78.6569],\n",
    "    'Haryana': [29.0588, 76.0856],\n",
    "    'Bihar': [25.0961, 85.3131],\n",
    "    'Telangana': [18.1124, 79.0193],\n",
    "    'Odisha': [20.9517, 85.0985],\n",
    "    'Punjab': [31.1471, 75.3412],\n",
    "    'Assam': [26.2006, 92.9376],\n",
    "    'Jharkhand': [23.6102, 85.2799],\n",
    "    'Uttarakhand': [30.0668, 79.0193],\n",
    "    'Chhattisgarh': [21.2787, 81.8661],\n",
    "    'Himachal Pradesh': [31.1048, 77.1734],\n",
    "    'Goa': [15.2993, 74.1240],\n",
    "    'Jammu and Kashmir': [33.7782, 76.5762],\n",
    "    'Puducherry': [11.9416, 79.8083],\n",
    "    'Tripura': [23.9408, 91.9882],\n",
    "    'Chandigarh': [30.7333, 76.7794],\n",
    "    'Manipur': [24.6637, 93.9063],\n",
    "    'Meghalaya': [25.4670, 91.3662],\n",
    "    'Nagaland': [26.1584, 94.5624],\n",
    "    'Arunachal Pradesh': [28.2180, 94.7278],\n",
    "    'Mizoram': [23.1645, 92.9376],\n",
    "    'Sikkim': [27.5330, 88.5122],\n",
    "    'Dadra and Nagar Haveli': [20.1809, 73.0169],\n",
    "    'Daman and Diu': [20.4283, 72.8397],\n",
    "    'Andaman and Nicobar Islands': [11.7401, 92.6586],\n",
    "    'Lakshadweep': [10.5667, 72.6417],\n",
    "    'Ladakh': [34.1526, 77.5770]\n",
    "}\n",
    "\n",
    "# Create peak cases data for map visualization\n",
    "def create_peak_cases_data(covid2_wave2):\n",
    "    peak_data = []\n",
    "    \n",
    "    for state in covid2_wave2['State'].unique():\n",
    "        state_data = covid2_wave2[covid2_wave2['State'] == state]\n",
    "        \n",
    "        # Find peak metrics\n",
    "        peak_cases = state_data['Confirmed'].max()\n",
    "        peak_new_cases = state_data['New Cases'].max()\n",
    "        peak_deaths = state_data['Deaths'].max()\n",
    "        peak_date = state_data.loc[state_data['New Cases'].idxmax(), 'Date'] if not state_data['New Cases'].isna().all() else None\n",
    "        \n",
    "        # Calculate total metrics for the wave\n",
    "        total_cases = state_data['New Cases'].sum()\n",
    "        total_deaths = state_data['Deaths'].max() - state_data['Deaths'].min()\n",
    "        \n",
    "        # Get coordinates\n",
    "        if state in state_coordinates:\n",
    "            lat, lon = state_coordinates[state]\n",
    "            \n",
    "            peak_data.append({\n",
    "                'State': state,\n",
    "                'Peak_Daily_Cases': peak_new_cases,\n",
    "                'Peak_Date': peak_date,\n",
    "                'Total_Wave2_Cases': total_cases,\n",
    "                'Total_Wave2_Deaths': total_deaths,\n",
    "                'CFR': (total_deaths / total_cases * 100) if total_cases > 0 else 0,\n",
    "                'latitude': lat,\n",
    "                'longitude': lon\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(peak_data)\n",
    "\n",
    "# Create PyDeck visualization for peak COVID cases\n",
    "def create_peak_cases_map(peak_df):\n",
    "    # Normalize the radius values\n",
    "    peak_df['radius'] = peak_df['Peak_Daily_Cases'] / peak_df['Peak_Daily_Cases'].max() * 100000\n",
    "    \n",
    "    # Create the layer\n",
    "    layer = pdk.Layer(\n",
    "        \"ScatterplotLayer\",\n",
    "        peak_df,\n",
    "        get_position=[\"longitude\", \"latitude\"],\n",
    "        get_radius=\"radius\",\n",
    "        get_fill_color=[255, 0, 0, 140],  # Red with alpha\n",
    "        pickable=True,\n",
    "        opacity=0.8,\n",
    "        stroked=True,\n",
    "        filled=True,\n",
    "    )\n",
    "    \n",
    "    # Set the view state\n",
    "    view_state = pdk.ViewState(\n",
    "        longitude=78.9629, \n",
    "        latitude=22.5937,  # Center of India\n",
    "        zoom=4,\n",
    "        min_zoom=3,\n",
    "        max_zoom=10,\n",
    "        pitch=0,\n",
    "        bearing=0\n",
    "    )\n",
    "    \n",
    "    # Create the tooltip\n",
    "    tooltip = {\n",
    "        \"html\": \"<b>{State}</b><br>Peak Daily Cases: {Peak_Daily_Cases}<br>On: {Peak_Date}<br>Total Wave2 Cases: {Total_Wave2_Cases}<br>CFR: {CFR}%\",\n",
    "        \"style\": {\"backgroundColor\": \"steelblue\", \"color\": \"white\"}\n",
    "    }\n",
    "    \n",
    "    # Create the deck\n",
    "    deck = pdk.Deck(\n",
    "        layers=[layer],\n",
    "        initial_view_state=view_state,\n",
    "        tooltip=tooltip,\n",
    "        map_style=\"mapbox://styles/mapbox/light-v9\"\n",
    "    )\n",
    "    \n",
    "    return deck\n",
    "\n",
    "# Create vaccination data for map visualization\n",
    "def create_vaccination_data(merged_wave2):\n",
    "    # Group by state and date, then calculate stats\n",
    "    vax_data = merged_wave2.groupby(['State', 'Date']).agg({\n",
    "        'Total Doses Administered': 'max',\n",
    "        'First Dose Administered': 'max',\n",
    "        'Second Dose Administered': 'max',\n",
    "        # 'Male (Doses Administered)': 'max',\n",
    "        # 'Female (Doses Administered)': 'max'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Get the last record for each state to show final vaccination status\n",
    "    final_vax = vax_data.sort_values('Date').groupby('State').last().reset_index()\n",
    "    \n",
    "    # Add coordinates\n",
    "    final_vax_with_coords = []\n",
    "    for index, row in final_vax.iterrows():\n",
    "        state = row['State']\n",
    "        if state in state_coordinates:\n",
    "            lat, lon = state_coordinates[state]\n",
    "            new_row = row.to_dict()\n",
    "            new_row['latitude'] = lat\n",
    "            new_row['longitude'] = lon\n",
    "            final_vax_with_coords.append(new_row)\n",
    "    \n",
    "    return pd.DataFrame(final_vax_with_coords)\n",
    "\n",
    "# Create PyDeck visualization for vaccination data\n",
    "def create_vaccination_map(vax_data):\n",
    "    # Normalize for visualization\n",
    "    max_doses = vax_data['Total Doses Administered'].max()\n",
    "    vax_data['radius'] = vax_data['Total Doses Administered'] / max_doses * 100000\n",
    "    \n",
    "    layer = pdk.Layer(\n",
    "        \"ScatterplotLayer\",\n",
    "        vax_data,\n",
    "        get_position=[\"longitude\", \"latitude\"],\n",
    "        get_radius=\"radius\",\n",
    "        get_fill_color=[0, 128, 255, 140],  # Blue with alpha\n",
    "        pickable=True,\n",
    "        opacity=0.8,\n",
    "        stroked=True,\n",
    "        filled=True,\n",
    "    )\n",
    "    \n",
    "    view_state = pdk.ViewState(\n",
    "        longitude=78.9629, \n",
    "        latitude=22.5937,  # Center of India\n",
    "        zoom=4,\n",
    "        min_zoom=3,\n",
    "        max_zoom=10,\n",
    "        pitch=0,\n",
    "        bearing=0\n",
    "    )\n",
    "    \n",
    "    tooltip = {\n",
    "        \"html\": \"<b>{State}</b><br>Total Doses: {Total Doses Administered:,.0f}<br>First Doses: {First Dose Administered:,.0f}<br>Second Doses: {Second Dose Administered:,.0f}\",\n",
    "        \"style\": {\"backgroundColor\": \"royalblue\", \"color\": \"white\"}\n",
    "    }\n",
    "    \n",
    "    deck = pdk.Deck(\n",
    "        layers=[layer],\n",
    "        initial_view_state=view_state,\n",
    "        tooltip=tooltip,\n",
    "        map_style=\"mapbox://styles/mapbox/light-v9\"\n",
    "    )\n",
    "    \n",
    "    return deck\n",
    "\n",
    "# # Create CFR (Case Fatality Rate) Choropleth\n",
    "# def create_cfr_choropleth(peak_df):\n",
    "#     fig = px.choropleth(\n",
    "#         peak_df,\n",
    "#         locations=\"State\",\n",
    "#         locationmode=\"country names\",\n",
    "#         color=\"CFR\",\n",
    "#         hover_name=\"State\",\n",
    "#         hover_data=[\"Total_Wave2_Cases\", \"Total_Wave2_Deaths\"],\n",
    "#         title=\"COVID-19 Case Fatality Rate by State (Second Wave)\",\n",
    "#         color_continuous_scale=\"Reds\",\n",
    "#         labels={\"CFR\": \"Case Fatality Rate (%)\"}\n",
    "#     )\n",
    "    \n",
    "#     fig.update_geos(\n",
    "#         visible=False,\n",
    "#         projection_type=\"mercator\",\n",
    "#         lonaxis_range=[68, 98],\n",
    "#         lataxis_range=[6, 38]\n",
    "#     )\n",
    "    \n",
    "#     fig.update_layout(\n",
    "#         title_x=0.5,\n",
    "#         margin={\"r\": 0, \"t\": 30, \"l\": 0, \"b\": 0},\n",
    "#         coloraxis_colorbar=dict(title=\"CFR (%)\"),\n",
    "#         height=600\n",
    "#     )\n",
    "    \n",
    "#     return fig\n",
    "\n",
    "# Create time series visualization for top states\n",
    "def create_time_series_chart(covid2_wave2):\n",
    "    # Get top 5 states by total cases\n",
    "    top_states = covid2_wave2.groupby('State')['Confirmed'].max().nlargest(5).index.tolist()\n",
    "    \n",
    "    # Filter data for these states\n",
    "    top_states_data = covid2_wave2[covid2_wave2['State'].isin(top_states)]\n",
    "    \n",
    "    # Create a time series chart\n",
    "    fig = px.line(\n",
    "        top_states_data, \n",
    "        x='Date', \n",
    "        y='New Cases',\n",
    "        color='State',\n",
    "        title='Daily New COVID-19 Cases in Top 5 States (Second Wave)',\n",
    "        labels={'New Cases': 'Daily New Cases', 'Date': 'Date'}\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='New Cases',\n",
    "        legend_title='State',\n",
    "        hovermode='x unified',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create vaccination progress chart over time\n",
    "def create_vaccination_progress_chart(merged_wave2):\n",
    "    # Group by date and sum vaccination data across states\n",
    "    vax_progress = merged_wave2.groupby('Date')[\n",
    "        ['Total Doses Administered', 'First Dose Administered', 'Second Dose Administered']\n",
    "    ].sum().reset_index()\n",
    "    \n",
    "    # Replace NaN with 0\n",
    "    vax_progress = vax_progress.fillna(0)\n",
    "    \n",
    "    # Create the plot\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=vax_progress['Date'], \n",
    "        y=vax_progress['First Dose Administered'],\n",
    "        mode='lines',\n",
    "        name='First Dose',\n",
    "        line=dict(width=2, color='blue')\n",
    "    ))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=vax_progress['Date'], \n",
    "        y=vax_progress['Second Dose Administered'],\n",
    "        mode='lines',\n",
    "        name='Second Dose',\n",
    "        line=dict(width=2, color='green')\n",
    "    ))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=vax_progress['Date'], \n",
    "        y=vax_progress['Total Doses Administered'],\n",
    "        mode='lines',\n",
    "        name='Total Doses',\n",
    "        line=dict(width=3, color='red')\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Cumulative COVID-19 Vaccination Progress (Second Wave)',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Number of Doses',\n",
    "        legend_title='Dose Type',\n",
    "        hovermode='x unified',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create testing vs positivity rate chart\n",
    "def create_testing_positivity_chart(testing_data):\n",
    "    # Calculate positivity rate\n",
    "    testing_data['Positivity_Rate'] = (testing_data['Positive'] / testing_data['Total Samples']) * 100\n",
    "    \n",
    "    # Group by state and calculate average positivity rate\n",
    "    state_positivity = testing_data.groupby('State')['Positivity_Rate'].mean().reset_index()\n",
    "    state_positivity = state_positivity.sort_values('Positivity_Rate', ascending=False)\n",
    "    \n",
    "    # Create bar chart\n",
    "    fig = px.bar(\n",
    "        state_positivity.head(15),  # Top 15 states\n",
    "        x='State',\n",
    "        y='Positivity_Rate',\n",
    "        title='Average COVID-19 Test Positivity Rate by State (Second Wave)',\n",
    "        color='Positivity_Rate',\n",
    "        color_continuous_scale='Reds',\n",
    "        labels={'Positivity_Rate': 'Positivity Rate (%)'}\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_title='State',\n",
    "        yaxis_title='Positivity Rate (%)',\n",
    "        xaxis={'categoryorder':'total descending'},\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create recovery rate vs vaccination rate scatter plot\n",
    "def create_recovery_vaccination_scatter(merged_wave2):\n",
    "    # Calculate recovery rate and vaccination rate by state\n",
    "    state_metrics = []\n",
    "    \n",
    "    for state in merged_wave2['State'].unique():\n",
    "        state_data = merged_wave2[merged_wave2['State'] == state].sort_values('Date')\n",
    "        \n",
    "        if len(state_data) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Calculate metrics\n",
    "        first_record = state_data.iloc[0]\n",
    "        last_record = state_data.iloc[-1]\n",
    "        \n",
    "        # Recovery rate\n",
    "        total_confirmed = last_record['Confirmed'] - first_record['Confirmed']\n",
    "        total_recovered = last_record['Recovered'] - first_record['Recovered']\n",
    "        \n",
    "        if total_confirmed > 0:\n",
    "            recovery_rate = (total_recovered / total_confirmed) * 100\n",
    "        else:\n",
    "            recovery_rate = 0\n",
    "            \n",
    "        # Vaccination rate\n",
    "        if 'Total Doses Administered' in state_data.columns and not pd.isna(last_record['Total Doses Administered']):\n",
    "            vax_rate = last_record['Total Doses Administered']\n",
    "        else:\n",
    "            vax_rate = 0\n",
    "            \n",
    "        state_metrics.append({\n",
    "            'State': state,\n",
    "            'Recovery_Rate': recovery_rate,\n",
    "            'Vaccination_Rate': vax_rate,\n",
    "            'Total_Cases': total_confirmed\n",
    "        })\n",
    "    \n",
    "    state_metrics_df = pd.DataFrame(state_metrics)\n",
    "    \n",
    "    # Create scatter plot\n",
    "    fig = px.scatter(\n",
    "        state_metrics_df,\n",
    "        x='Vaccination_Rate',\n",
    "        y='Recovery_Rate',\n",
    "        size='Total_Cases',\n",
    "        color='Total_Cases',\n",
    "        hover_name='State',\n",
    "        text='State',\n",
    "        title='Relationship Between Vaccination Rate and Recovery Rate by State',\n",
    "        labels={\n",
    "            'Vaccination_Rate': 'Total Vaccine Doses',\n",
    "            'Recovery_Rate': 'Recovery Rate (%)',\n",
    "            'Total_Cases': 'Total Cases'\n",
    "        },\n",
    "        color_continuous_scale='Viridis'\n",
    "    )\n",
    "    \n",
    "    fig.update_traces(textposition='top center')\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_title='Total Vaccine Doses',\n",
    "        yaxis_title='Recovery Rate (%)',\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# # Create gender distribution pie chart\n",
    "# def create_gender_distribution_chart(gender_data):\n",
    "#     # Count cases by gender\n",
    "#     gender_counts = gender_data['Gender'].value_counts()\n",
    "    \n",
    "#     # Create pie chart\n",
    "#     fig = px.pie(\n",
    "#         names=gender_counts.index,\n",
    "#         values=gender_counts.values,\n",
    "#         title='COVID-19 Cases by Gender (Second Wave)',\n",
    "#         color_discrete_sequence=px.colors.qualitative.Set3\n",
    "#     )\n",
    "    \n",
    "#     fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "    \n",
    "#     fig.update_layout(\n",
    "#         legend_title='Gender',\n",
    "#         height=400\n",
    "#     )\n",
    "    \n",
    "#     return fig\n",
    "\n",
    "# Create age group distribution chart\n",
    "def create_age_distribution_chart(age_group_data):\n",
    "    # Sort age groups properly\n",
    "    age_group_data['sort_order'] = age_group_data['AgeGroup'].apply(\n",
    "        lambda x: int(x.split('-')[0]) if '-' in x else 0\n",
    "    )\n",
    "    \n",
    "    sorted_data = age_group_data.sort_values('sort_order')\n",
    "    \n",
    "    # Create bar chart\n",
    "    fig = px.bar(\n",
    "        sorted_data,\n",
    "        x='AgeGroup',\n",
    "        y='TotalCases',\n",
    "        title='COVID-19 Cases by Age Group (Second Wave)',\n",
    "        color='TotalCases',\n",
    "        labels={'TotalCases': 'Total Cases', 'AgeGroup': 'Age Group'},\n",
    "        color_continuous_scale='Blues'\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_title='Age Group',\n",
    "        yaxis_title='Total Cases',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create detailed state metrics table\n",
    "def create_state_metrics_table(covid2_wave2):\n",
    "    # Calculate metrics by state\n",
    "    state_metrics = []\n",
    "    \n",
    "    for state in covid2_wave2['State'].unique():\n",
    "        state_data = covid2_wave2[covid2_wave2['State'] == state].sort_values('Date')\n",
    "        \n",
    "        if len(state_data) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Calculate metrics\n",
    "        first_record = state_data.iloc[0]\n",
    "        last_record = state_data.iloc[-1]\n",
    "        peak_record_index = state_data['New Cases'].idxmax() if not state_data['New Cases'].isna().all() else 0\n",
    "        \n",
    "        if peak_record_index != 0:\n",
    "            peak_record = state_data.loc[peak_record_index]\n",
    "            peak_date = peak_record['Date']\n",
    "            peak_cases = peak_record['New Cases']\n",
    "        else:\n",
    "            peak_date = None\n",
    "            peak_cases = 0\n",
    "        \n",
    "        # Basic metrics\n",
    "        total_cases = last_record['Confirmed'] - first_record['Confirmed']\n",
    "        total_deaths = last_record['Deaths'] - first_record['Deaths']\n",
    "        total_recovered = last_record['Recovered'] - first_record['Recovered'] if 'Recovered' in state_data.columns else 0\n",
    "        \n",
    "        # Calculate rates\n",
    "        cfr = (total_deaths / total_cases * 100) if total_cases > 0 else 0\n",
    "        recovery_rate = (total_recovered / total_cases * 100) if total_cases > 0 else 0\n",
    "        \n",
    "        state_metrics.append({\n",
    "            'State': state,\n",
    "            'Total_Cases': total_cases,\n",
    "            'Total_Deaths': total_deaths,\n",
    "            'Peak_Daily_Cases': peak_cases,\n",
    "            'Peak_Date': peak_date,\n",
    "            'CFR': cfr,\n",
    "            'Recovery_Rate': recovery_rate\n",
    "        })\n",
    "    \n",
    "    state_metrics_df = pd.DataFrame(state_metrics)\n",
    "    \n",
    "    # Create table\n",
    "    fig = go.Figure(data=[go.Table(\n",
    "        header=dict(\n",
    "            values=['State', 'Total Cases', 'Total Deaths', 'Peak Daily Cases', 'Peak Date', 'CFR (%)', 'Recovery Rate (%)'],\n",
    "            fill_color='paleturquoise',\n",
    "            align='left'\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[\n",
    "                state_metrics_df['State'],\n",
    "                state_metrics_df['Total_Cases'].apply(lambda x: f\"{x:,.0f}\"),\n",
    "                state_metrics_df['Total_Deaths'].apply(lambda x: f\"{x:,.0f}\"),\n",
    "                state_metrics_df['Peak_Daily_Cases'].apply(lambda x: f\"{x:,.0f}\"),\n",
    "                state_metrics_df['Peak_Date'].apply(lambda x: x.strftime('%Y-%m-%d') if pd.notnull(x) else 'N/A'),\n",
    "                state_metrics_df['CFR'].apply(lambda x: f\"{x:.2f}\"),\n",
    "                state_metrics_df['Recovery_Rate'].apply(lambda x: f\"{x:.2f}\")\n",
    "            ],\n",
    "            fill_color='lavender',\n",
    "            align='left'\n",
    "        )\n",
    "    )])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Detailed COVID-19 Metrics by State (Second Wave)',\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create a dashboard using Dash\n",
    "def create_dashboard():\n",
    "    # Load and prepare data\n",
    "    datasets = load_datasets()\n",
    "    wave2_datasets = filter_wave2_data(datasets)\n",
    "    \n",
    "    # Create datasets for visualizations\n",
    "    peak_cases_df = create_peak_cases_data(wave2_datasets['covid2'])\n",
    "    vaccination_df = create_vaccination_data(wave2_datasets['merged'])\n",
    "    \n",
    "    # Create PyDeck visualizations\n",
    "    peak_cases_map = create_peak_cases_map(peak_cases_df)\n",
    "    vaccination_map = create_vaccination_map(vaccination_df)\n",
    "    \n",
    "    # Save PyDeck visualizations to HTML files\n",
    "    peak_cases_map.to_html(\"peak_cases_map.html\")\n",
    "    vaccination_map.to_html(\"vaccination_map.html\")\n",
    "    \n",
    "    # Create Plotly visualizations\n",
    "    # cfr_choropleth = create_cfr_choropleth(peak_cases_df)\n",
    "    time_series_chart = create_time_series_chart(wave2_datasets['covid2'])\n",
    "    vaccination_progress_chart = create_vaccination_progress_chart(wave2_datasets['merged'])\n",
    "    testing_positivity_chart = create_testing_positivity_chart(wave2_datasets['testing'])\n",
    "    recovery_vaccination_scatter = create_recovery_vaccination_scatter(wave2_datasets['merged'])\n",
    "    # gender_distribution_chart = create_gender_distribution_chart(wave2_datasets['gender'])\n",
    "    age_distribution_chart = create_age_distribution_chart(wave2_datasets['age_group'])\n",
    "    state_metrics_table = create_state_metrics_table(wave2_datasets['covid2'])\n",
    "    \n",
    "    # Initialize Dash app\n",
    "    app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "    \n",
    "    # App layout\n",
    "    app.layout = dbc.Container([\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                html.H1(\"COVID-19 Second Wave in India (March-July 2021)\",\n",
    "                       style={'textAlign': 'center', 'color': '#2c3e50', 'marginTop': 20})\n",
    "            ], width=12)\n",
    "        ]),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"COVID-19 Peak Daily Cases by State\"),\n",
    "                    dbc.CardBody([\n",
    "                        html.Iframe(\n",
    "                            id='peak-cases-map',\n",
    "                            srcDoc=open('peak_cases_map.html', 'r').read(),\n",
    "                            style={'width': '100%', 'height': '400px'}\n",
    "                        )\n",
    "                    ])\n",
    "                ])\n",
    "            ], width=6),\n",
    "            \n",
    "        #     dbc.Col([\n",
    "        #         dbc.Card([\n",
    "        #             dbc.CardHeader(\"COVID-19 Case Fatality Rate by State\"),\n",
    "        #             dbc.CardBody([\n",
    "        #                 dcc.Graph(figure=cfr_choropleth)\n",
    "        #             ])\n",
    "        #         ])\n",
    "        #     ], width=6)\n",
    "        # ], className='mb-4'),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Daily COVID-19 Cases in Top 5 States\"),\n",
    "                    dbc.CardBody([\n",
    "                        dcc.Graph(figure=time_series_chart)\n",
    "                    ])\n",
    "                ])\n",
    "            ], width=12)\n",
    "        ], className='mb-4'),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Vaccination Progress Across India\"),\n",
    "                    dbc.CardBody([\n",
    "                        html.Iframe(\n",
    "                            id='vax-map',\n",
    "                            srcDoc=open('vaccination_map.html', 'r').read(),\n",
    "                            style={'width': '100%', 'height': '400px'}\n",
    "                        )\n",
    "                    ])\n",
    "                ])\n",
    "            ], width=6),\n",
    "            \n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Vaccination Progress Over Time\"),\n",
    "                    dbc.CardBody([\n",
    "                        dcc.Graph(figure=vaccination_progress_chart)\n",
    "                    ])\n",
    "                ])\n",
    "            ], width=6)\n",
    "        ], className='mb-4'),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Test Positivity Rate by State\"),\n",
    "                    dbc.CardBody([\n",
    "                        dcc.Graph(figure=testing_positivity_chart)\n",
    "                    ])\n",
    "                ])\n",
    "            ], width=6),\n",
    "            \n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Vaccination vs Recovery Rate\"),\n",
    "                    dbc.CardBody([\n",
    "                        dcc.Graph(figure=recovery_vaccination_scatter)\n",
    "                    ])\n",
    "                ])\n",
    "            ], width=6)\n",
    "        ], className='mb-4'),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Cases by Gender\"),\n",
    "                    dbc.CardBody([\n",
    "                        dcc.Graph(figure=gender_distribution_chart)\n",
    "                    ])\n",
    "                ])\n",
    "            ], width=6),\n",
    "            \n",
    "        #     dbc.Col([\n",
    "        #         dbc.Card([\n",
    "        #             dbc.CardHeader(\"Cases by Age Group\"),\n",
    "        #             dbc.CardBody([\n",
    "        #                 dcc.Graph(figure=age_distribution_chart)\n",
    "        #             ])\n",
    "        #         ])\n",
    "        #     ], width=6)\n",
    "        # ], className='mb-4'),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Detailed State Metrics\"),\n",
    "                    dbc.CardBody([\n",
    "                        dcc.Graph(figure=state_metrics_table)\n",
    "                    ])\n",
    "                ])\n",
    "            ], width=12)\n",
    "        ], className='mb-4')\n",
    "    ], fluid=True)\n",
    "    \n",
    "    return app\n",
    "\n",
    "# Main function to run the dashboard\n",
    "if __name__ == '__main__':\n",
    "    app = create_dashboard()\n",
    "    app.run(debug=True)\n",
    "    \n",
    "    print(\"Dashboard is running. Open http://127.0.0.1:8050/ in your web browser to view it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92aba30d-855d-4f97-9b71-7cb0a21b7c47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\AppData\\Local\\Temp\\ipykernel_24608\\2528752653.py:322: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1d14ba2cb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard is running. Open http://127.0.0.1:8050/ in your web browser to view it.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydeck as pdk\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "import dash_bootstrap_components as dbc\n",
    "import json\n",
    "import base64\n",
    "\n",
    "# Load datasets\n",
    "def load_datasets():\n",
    "    covid_state_data = pd.read_csv('covid cases by state_Full Data_data (1).csv')\n",
    "    covid_india = pd.read_csv('covid_19_india.csv')\n",
    "    vaccine_data = pd.read_csv('covid_vaccine_statewise.csv')\n",
    "    covid2_new = pd.read_csv('Covid2_new.csv')\n",
    "    testing_data = pd.read_csv('StatewiseTestingDetails.csv')\n",
    "    merged_data = pd.read_csv('merged_covid_vaccine_data.csv')\n",
    "    age_group_data = pd.read_csv('AgeGroupDetails.csv')\n",
    "    \n",
    "    # Fix date columns\n",
    "    covid_state_data['Date'] = pd.to_datetime(covid_state_data['Date'])\n",
    "    covid_india['Date'] = pd.to_datetime(covid_india['Date'])\n",
    "    covid2_new['Date'] = pd.to_datetime(covid2_new['Date'])\n",
    "    testing_data['Date'] = pd.to_datetime(testing_data['Date'])\n",
    "    merged_data['Date'] = pd.to_datetime(merged_data['Date'])\n",
    "    \n",
    "    return {\n",
    "        'covid_state': covid_state_data,\n",
    "        'covid_india': covid_india,\n",
    "        'vaccine': vaccine_data,\n",
    "        'covid2': covid2_new,\n",
    "        'testing': testing_data,\n",
    "        'merged': merged_data,\n",
    "        'age_group': age_group_data,\n",
    "    }\n",
    "\n",
    "# Filter for second wave period (March 2021 to July 2021)\n",
    "def filter_wave2_data(datasets):\n",
    "    start_date = '2021-03-01'\n",
    "    end_date = '2021-07-31'\n",
    "    \n",
    "    wave2_datasets = {}\n",
    "    \n",
    "    for key, df in datasets.items():\n",
    "        if 'Date' in df.columns:\n",
    "            wave2_datasets[key] = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "        else:\n",
    "            wave2_datasets[key] = df\n",
    "    \n",
    "    return wave2_datasets\n",
    "\n",
    "# State coordinates for mapping (approximate centroids)\n",
    "state_coordinates = {\n",
    "    'Maharashtra': [19.7515, 75.7139],\n",
    "    'Kerala': [10.8505, 76.2711],\n",
    "    'Karnataka': [15.3173, 75.7139],\n",
    "    'Tamil Nadu': [11.1271, 78.6569],\n",
    "    'Andhra Pradesh': [15.9129, 79.7400],\n",
    "    'Uttar Pradesh': [26.8467, 80.9462],\n",
    "    'Delhi': [28.7041, 77.1025],\n",
    "    'West Bengal': [22.9868, 87.8550],\n",
    "    'Rajasthan': [27.0238, 74.2179],\n",
    "    'Gujarat': [22.2587, 71.1924],\n",
    "    'Madhya Pradesh': [22.9734, 78.6569],\n",
    "    'Haryana': [29.0588, 76.0856],\n",
    "    'Bihar': [25.0961, 85.3131],\n",
    "    'Telangana': [18.1124, 79.0193],\n",
    "    'Odisha': [20.9517, 85.0985],\n",
    "    'Punjab': [31.1471, 75.3412],\n",
    "    'Assam': [26.2006, 92.9376],\n",
    "    'Jharkhand': [23.6102, 85.2799],\n",
    "    'Uttarakhand': [30.0668, 79.0193],\n",
    "    'Chhattisgarh': [21.2787, 81.8661],\n",
    "    'Himachal Pradesh': [31.1048, 77.1734],\n",
    "    'Goa': [15.2993, 74.1240],\n",
    "    'Jammu and Kashmir': [33.7782, 76.5762],\n",
    "    'Puducherry': [11.9416, 79.8083],\n",
    "    'Tripura': [23.9408, 91.9882],\n",
    "    'Chandigarh': [30.7333, 76.7794],\n",
    "    'Manipur': [24.6637, 93.9063],\n",
    "    'Meghalaya': [25.4670, 91.3662],\n",
    "    'Nagaland': [26.1584, 94.5624],\n",
    "    'Arunachal Pradesh': [28.2180, 94.7278],\n",
    "    'Mizoram': [23.1645, 92.9376],\n",
    "    'Sikkim': [27.5330, 88.5122],\n",
    "    'Dadra and Nagar Haveli': [20.1809, 73.0169],\n",
    "    'Daman and Diu': [20.4283, 72.8397],\n",
    "    'Andaman and Nicobar Islands': [11.7401, 92.6586],\n",
    "    'Lakshadweep': [10.5667, 72.6417],\n",
    "    'Ladakh': [34.1526, 77.5770]\n",
    "}\n",
    "\n",
    "# Create peak cases data for map visualization\n",
    "def create_peak_cases_data(covid2_wave2):\n",
    "    peak_data = []\n",
    "    \n",
    "    for state in covid2_wave2['State'].unique():\n",
    "        state_data = covid2_wave2[covid2_wave2['State'] == state]\n",
    "        \n",
    "        # Find peak metrics\n",
    "        peak_cases = state_data['Confirmed'].max()\n",
    "        peak_new_cases = state_data['New Cases'].max()\n",
    "        peak_deaths = state_data['Deaths'].max()\n",
    "        peak_date = state_data.loc[state_data['New Cases'].idxmax(), 'Date'] if not state_data['New Cases'].isna().all() else None\n",
    "        \n",
    "        # Calculate total metrics for the wave\n",
    "        total_cases = state_data['New Cases'].sum()\n",
    "        total_deaths = state_data['Deaths'].max() - state_data['Deaths'].min()\n",
    "        \n",
    "        # Get coordinates\n",
    "        if state in state_coordinates:\n",
    "            lat, lon = state_coordinates[state]\n",
    "            \n",
    "            peak_data.append({\n",
    "                'State': state,\n",
    "                'Peak_Daily_Cases': peak_new_cases,\n",
    "                'Peak_Date': peak_date,\n",
    "                'Total_Wave2_Cases': total_cases,\n",
    "                'Total_Wave2_Deaths': total_deaths,\n",
    "                'CFR': (total_deaths / total_cases * 100) if total_cases > 0 else 0,\n",
    "                'latitude': lat,\n",
    "                'longitude': lon\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(peak_data)\n",
    "\n",
    "# Create PyDeck visualization for peak COVID cases\n",
    "def create_peak_cases_map(peak_df):\n",
    "    # Normalize the radius values\n",
    "    peak_df['radius'] = peak_df['Peak_Daily_Cases'] / peak_df['Peak_Daily_Cases'].max() * 100000\n",
    "    \n",
    "    # Create the layer\n",
    "    layer = pdk.Layer(\n",
    "        \"ScatterplotLayer\",\n",
    "        peak_df,\n",
    "        get_position=[\"longitude\", \"latitude\"],\n",
    "        get_radius=\"radius\",\n",
    "        get_fill_color=[255, 0, 0, 140],  # Red with alpha\n",
    "        pickable=True,\n",
    "        opacity=0.8,\n",
    "        stroked=True,\n",
    "        filled=True,\n",
    "    )\n",
    "    \n",
    "    # Set the view state\n",
    "    view_state = pdk.ViewState(\n",
    "        longitude=78.9629, \n",
    "        latitude=22.5937,  # Center of India\n",
    "        zoom=4,\n",
    "        min_zoom=3,\n",
    "        max_zoom=10,\n",
    "        pitch=0,\n",
    "        bearing=0\n",
    "    )\n",
    "    \n",
    "    # Create the tooltip\n",
    "    tooltip = {\n",
    "        \"html\": \"<b>{State}</b><br>Peak Daily Cases: {Peak_Daily_Cases}<br>On: {Peak_Date}<br>Total Wave2 Cases: {Total_Wave2_Cases}<br>CFR: {CFR}%\",\n",
    "        \"style\": {\"backgroundColor\": \"steelblue\", \"color\": \"white\"}\n",
    "    }\n",
    "    \n",
    "    # Create the deck\n",
    "    deck = pdk.Deck(\n",
    "        layers=[layer],\n",
    "        initial_view_state=view_state,\n",
    "        tooltip=tooltip,\n",
    "        map_style=\"mapbox://styles/mapbox/light-v9\"\n",
    "    )\n",
    "    \n",
    "    return deck\n",
    "\n",
    "# Create vaccination data for map visualization\n",
    "def create_vaccination_data(merged_wave2):\n",
    "    # Group by state and date, then calculate stats\n",
    "    vax_data = merged_wave2.groupby(['State', 'Date']).agg({\n",
    "        'Total Doses Administered': 'max',\n",
    "        'First Dose Administered': 'max',\n",
    "        'Second Dose Administered': 'max',\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Get the last record for each state to show final vaccination status\n",
    "    final_vax = vax_data.sort_values('Date').groupby('State').last().reset_index()\n",
    "    \n",
    "    # Add coordinates\n",
    "    final_vax_with_coords = []\n",
    "    for index, row in final_vax.iterrows():\n",
    "        state = row['State']\n",
    "        if state in state_coordinates:\n",
    "            lat, lon = state_coordinates[state]\n",
    "            new_row = row.to_dict()\n",
    "            new_row['latitude'] = lat\n",
    "            new_row['longitude'] = lon\n",
    "            final_vax_with_coords.append(new_row)\n",
    "    \n",
    "    return pd.DataFrame(final_vax_with_coords)\n",
    "\n",
    "# Create PyDeck visualization for vaccination data\n",
    "def create_vaccination_map(vax_data):\n",
    "    # Normalize for visualization\n",
    "    max_doses = vax_data['Total Doses Administered'].max()\n",
    "    vax_data['radius'] = vax_data['Total Doses Administered'] / max_doses * 100000\n",
    "    \n",
    "    layer = pdk.Layer(\n",
    "        \"ScatterplotLayer\",\n",
    "        vax_data,\n",
    "        get_position=[\"longitude\", \"latitude\"],\n",
    "        get_radius=\"radius\",\n",
    "        get_fill_color=[0, 128, 255, 140],  # Blue with alpha\n",
    "        pickable=True,\n",
    "        opacity=0.8,\n",
    "        stroked=True,\n",
    "        filled=True,\n",
    "    )\n",
    "    \n",
    "    view_state = pdk.ViewState(\n",
    "        longitude=78.9629, \n",
    "        latitude=22.5937,  # Center of India\n",
    "        zoom=4,\n",
    "        min_zoom=3,\n",
    "        max_zoom=10,\n",
    "        pitch=0,\n",
    "        bearing=0\n",
    "    )\n",
    "    \n",
    "    tooltip = {\n",
    "        \"html\": \"<b>{State}</b><br>Total Doses: {Total Doses Administered:,.0f}<br>First Doses: {First Dose Administered:,.0f}<br>Second Doses: {Second Dose Administered:,.0f}\",\n",
    "        \"style\": {\"backgroundColor\": \"royalblue\", \"color\": \"white\"}\n",
    "    }\n",
    "    \n",
    "    deck = pdk.Deck(\n",
    "        layers=[layer],\n",
    "        initial_view_state=view_state,\n",
    "        tooltip=tooltip,\n",
    "        map_style=\"mapbox://styles/mapbox/light-v9\"\n",
    "    )\n",
    "    \n",
    "    return deck\n",
    "\n",
    "# Create time series visualization for top states\n",
    "def create_time_series_chart(covid2_wave2):\n",
    "    # Get top 5 states by total cases\n",
    "    top_states = covid2_wave2.groupby('State')['Confirmed'].max().nlargest(5).index.tolist()\n",
    "    \n",
    "    # Filter data for these states\n",
    "    top_states_data = covid2_wave2[covid2_wave2['State'].isin(top_states)]\n",
    "    \n",
    "    # Create a time series chart\n",
    "    fig = px.line(\n",
    "        top_states_data, \n",
    "        x='Date', \n",
    "        y='New Cases',\n",
    "        color='State',\n",
    "        title='Daily New COVID-19 Cases in Top 5 States (Second Wave)',\n",
    "        labels={'New Cases': 'Daily New Cases', 'Date': 'Date'}\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='New Cases',\n",
    "        legend_title='State',\n",
    "        hovermode='x unified',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create vaccination progress chart over time\n",
    "def create_vaccination_progress_chart(merged_wave2):\n",
    "    # Group by date and sum vaccination data across states\n",
    "    vax_progress = merged_wave2.groupby('Date')[\n",
    "        ['Total Doses Administered', 'First Dose Administered', 'Second Dose Administered']\n",
    "    ].sum().reset_index()\n",
    "    \n",
    "    # Replace NaN with 0\n",
    "    vax_progress = vax_progress.fillna(0)\n",
    "    \n",
    "    # Create the plot\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=vax_progress['Date'], \n",
    "        y=vax_progress['First Dose Administered'],\n",
    "        mode='lines',\n",
    "        name='First Dose',\n",
    "        line=dict(width=2, color='blue')\n",
    "    ))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=vax_progress['Date'], \n",
    "        y=vax_progress['Second Dose Administered'],\n",
    "        mode='lines',\n",
    "        name='Second Dose',\n",
    "        line=dict(width=2, color='green')\n",
    "    ))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=vax_progress['Date'], \n",
    "        y=vax_progress['Total Doses Administered'],\n",
    "        mode='lines',\n",
    "        name='Total Doses',\n",
    "        line=dict(width=3, color='red')\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Cumulative COVID-19 Vaccination Progress (Second Wave)',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Number of Doses',\n",
    "        legend_title='Dose Type',\n",
    "        hovermode='x unified',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create testing vs positivity rate chart\n",
    "def create_testing_positivity_chart(testing_data):\n",
    "    # Calculate positivity rate\n",
    "    testing_data['Positivity_Rate'] = (testing_data['Positive'] / testing_data['TotalSamples']) * 100\n",
    "    \n",
    "    # Group by state and calculate average positivity rate\n",
    "    state_positivity = testing_data.groupby('State')['Positivity_Rate'].mean().reset_index()\n",
    "    state_positivity = state_positivity.sort_values('Positivity_Rate', ascending=False)\n",
    "    \n",
    "    # Create bar chart\n",
    "    fig = px.bar(\n",
    "        state_positivity.head(15),  # Top 15 states\n",
    "        x='State',\n",
    "        y='Positivity_Rate',\n",
    "        title='Average COVID-19 Test Positivity Rate by State (Second Wave)',\n",
    "        color='Positivity_Rate',\n",
    "        color_continuous_scale='Reds',\n",
    "        labels={'Positivity_Rate': 'Positivity Rate (%)'}\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_title='State',\n",
    "        yaxis_title='Positivity Rate (%)',\n",
    "        xaxis={'categoryorder':'total descending'},\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create recovery rate vs vaccination rate scatter plot\n",
    "def create_recovery_vaccination_scatter(merged_wave2):\n",
    "    # Calculate recovery rate and vaccination rate by state\n",
    "    state_metrics = []\n",
    "    \n",
    "    for state in merged_wave2['State'].unique():\n",
    "        state_data = merged_wave2[merged_wave2['State'] == state].sort_values('Date')\n",
    "        \n",
    "        if len(state_data) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Calculate metrics\n",
    "        first_record = state_data.iloc[0]\n",
    "        last_record = state_data.iloc[-1]\n",
    "        \n",
    "        # Recovery rate\n",
    "        total_confirmed = last_record['Confirmed'] - first_record['Confirmed']\n",
    "        total_recovered = last_record['Recovered'] - first_record['Recovered']\n",
    "        \n",
    "        if total_confirmed > 0:\n",
    "            recovery_rate = (total_recovered / total_confirmed) * 100\n",
    "        else:\n",
    "            recovery_rate = 0\n",
    "            \n",
    "        # Vaccination rate\n",
    "        if 'Total Doses Administered' in state_data.columns and not pd.isna(last_record['Total Doses Administered']):\n",
    "            vax_rate = last_record['Total Doses Administered']\n",
    "        else:\n",
    "            vax_rate = 0\n",
    "            \n",
    "        state_metrics.append({\n",
    "            'State': state,\n",
    "            'Recovery_Rate': recovery_rate,\n",
    "            'Vaccination_Rate': vax_rate,\n",
    "            'Total_Cases': total_confirmed\n",
    "        })\n",
    "    \n",
    "    state_metrics_df = pd.DataFrame(state_metrics)\n",
    "    \n",
    "    # Create scatter plot\n",
    "    fig = px.scatter(\n",
    "        state_metrics_df,\n",
    "        x='Vaccination_Rate',\n",
    "        y='Recovery_Rate',\n",
    "        size='Total_Cases',\n",
    "        color='Total_Cases',\n",
    "        hover_name='State',\n",
    "        text='State',\n",
    "        title='Relationship Between Vaccination Rate and Recovery Rate by State',\n",
    "        labels={\n",
    "            'Vaccination_Rate': 'Total Vaccine Doses',\n",
    "            'Recovery_Rate': 'Recovery Rate (%)',\n",
    "            'Total_Cases': 'Total Cases'\n",
    "        },\n",
    "        color_continuous_scale='Viridis'\n",
    "    )\n",
    "    \n",
    "    fig.update_traces(textposition='top center')\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_title='Total Vaccine Doses',\n",
    "        yaxis_title='Recovery Rate (%)',\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create age group distribution chart\n",
    "def create_age_distribution_chart(age_group_data):\n",
    "    # Sort age groups properly\n",
    "    age_group_data['sort_order'] = age_group_data['AgeGroup'].apply(\n",
    "        lambda x: int(x.split('-')[0]) if '-' in x else 0\n",
    "    )\n",
    "    \n",
    "    sorted_data = age_group_data.sort_values('sort_order')\n",
    "    \n",
    "    # Create bar chart\n",
    "    fig = px.bar(\n",
    "        sorted_data,\n",
    "        x='AgeGroup',\n",
    "        y='TotalCases',\n",
    "        title='COVID-19 Cases by Age Group (Second Wave)',\n",
    "        color='TotalCases',\n",
    "        labels={'TotalCases': 'Total Cases', 'AgeGroup': 'Age Group'},\n",
    "        color_continuous_scale='Blues'\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_title='Age Group',\n",
    "        yaxis_title='Total Cases',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create detailed state metrics table\n",
    "def create_state_metrics_table(covid2_wave2):\n",
    "    # Calculate metrics by state\n",
    "    state_metrics = []\n",
    "    \n",
    "    for state in covid2_wave2['State'].unique():\n",
    "        state_data = covid2_wave2[covid2_wave2['State'] == state].sort_values('Date')\n",
    "        \n",
    "        if len(state_data) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Calculate metrics\n",
    "        first_record = state_data.iloc[0]\n",
    "        last_record = state_data.iloc[-1]\n",
    "        peak_record_index = state_data['New Cases'].idxmax() if not state_data['New Cases'].isna().all() else 0\n",
    "        \n",
    "        if peak_record_index != 0:\n",
    "            peak_record = state_data.loc[peak_record_index]\n",
    "            peak_date = peak_record['Date']\n",
    "            peak_cases = peak_record['New Cases']\n",
    "        else:\n",
    "            peak_date = None\n",
    "            peak_cases = 0\n",
    "        \n",
    "        # Basic metrics\n",
    "        total_cases = last_record['Confirmed'] - first_record['Confirmed']\n",
    "        total_deaths = last_record['Deaths'] - first_record['Deaths']\n",
    "        total_recovered = last_record['Recovered'] - first_record['Recovered'] if 'Recovered' in state_data.columns else 0\n",
    "        \n",
    "        # Calculate rates\n",
    "        cfr = (total_deaths / total_cases * 100) if total_cases > 0 else 0\n",
    "        recovery_rate = (total_recovered / total_cases * 100) if total_cases > 0 else 0\n",
    "        \n",
    "        state_metrics.append({\n",
    "            'State': state,\n",
    "            'Total_Cases': total_cases,\n",
    "            'Total_Deaths': total_deaths,\n",
    "            'Peak_Daily_Cases': peak_cases,\n",
    "            'Peak_Date': peak_date,\n",
    "            'CFR': cfr,\n",
    "            'Recovery_Rate': recovery_rate\n",
    "        })\n",
    "    \n",
    "    state_metrics_df = pd.DataFrame(state_metrics)\n",
    "    \n",
    "    # Create table\n",
    "    fig = go.Figure(data=[go.Table(\n",
    "        header=dict(\n",
    "            values=['State', 'Total Cases', 'Total Deaths', 'Peak Daily Cases', 'Peak Date', 'CFR (%)', 'Recovery Rate (%)'],\n",
    "            fill_color='paleturquoise',\n",
    "            align='left'\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[\n",
    "                state_metrics_df['State'],\n",
    "                state_metrics_df['Total_Cases'].apply(lambda x: f\"{x:,.0f}\"),\n",
    "                state_metrics_df['Total_Deaths'].apply(lambda x: f\"{x:,.0f}\"),\n",
    "                state_metrics_df['Peak_Daily_Cases'].apply(lambda x: f\"{x:,.0f}\"),\n",
    "                state_metrics_df['Peak_Date'].apply(lambda x: x.strftime('%Y-%m-%d') if pd.notnull(x) else 'N/A'),\n",
    "                state_metrics_df['CFR'].apply(lambda x: f\"{x:.2f}\"),\n",
    "                state_metrics_df['Recovery_Rate'].apply(lambda x: f\"{x:.2f}\")\n",
    "            ],\n",
    "            fill_color='lavender',\n",
    "            align='left'\n",
    "        )\n",
    "    )])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Detailed COVID-19 Metrics by State (Second Wave)',\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create a dashboard using Dash\n",
    "def create_dashboard():\n",
    "    # Load and prepare data\n",
    "    datasets = load_datasets()\n",
    "    wave2_datasets = filter_wave2_data(datasets)\n",
    "    \n",
    "    # Create datasets for visualizations\n",
    "    peak_cases_df = create_peak_cases_data(wave2_datasets['covid2'])\n",
    "    vaccination_df = create_vaccination_data(wave2_datasets['merged'])\n",
    "    \n",
    "    # Create PyDeck visualizations\n",
    "    peak_cases_map = create_peak_cases_map(peak_cases_df)\n",
    "    vaccination_map = create_vaccination_map(vaccination_df)\n",
    "    \n",
    "    # Save PyDeck visualizations to HTML files\n",
    "    peak_cases_map.to_html(\"peak_cases_map.html\")\n",
    "    vaccination_map.to_html(\"vaccination_map.html\")\n",
    "    \n",
    "    # Create Plotly visualizations\n",
    "    time_series_chart = create_time_series_chart(wave2_datasets['covid2'])\n",
    "    vaccination_progress_chart = create_vaccination_progress_chart(wave2_datasets['merged'])\n",
    "    testing_positivity_chart = create_testing_positivity_chart(wave2_datasets['testing'])\n",
    "    recovery_vaccination_scatter = create_recovery_vaccination_scatter(wave2_datasets['merged'])\n",
    "    age_distribution_chart = create_age_distribution_chart(wave2_datasets['age_group'])\n",
    "    state_metrics_table = create_state_metrics_table(wave2_datasets['covid2'])\n",
    "    \n",
    "    # Initialize Dash app\n",
    "    app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "    \n",
    "    # App layout\n",
    "    app.layout = dbc.Container([\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                html.H1(\"COVID-19 Second Wave in India (March-July 2021)\",\n",
    "                       style={'textAlign': 'center', 'color': '#2c3e50', 'marginTop': 20})\n",
    "            ], width=12)\n",
    "        ]),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"COVID-19 Peak Daily Cases by State\"),\n",
    "                    dbc.CardBody([\n",
    "                        html.Iframe(\n",
    "                            id='peak-cases-map',\n",
    "                            srcDoc=open('peak_cases_map.html', 'r').read(),\n",
    "                            style={'width': '100%', 'height': '400px'}\n",
    "                        )\n",
    "                    ])\n",
    "                ])\n",
    "            ], width=12)\n",
    "        ], className='mb-4'),\n",
    "               \n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Daily COVID-19 Cases in Top 5 States\"),\n",
    "                    dbc.CardBody([\n",
    "                        dcc.Graph(figure=time_series_chart)\n",
    "                    ])\n",
    "                ])\n",
    "            ], width=12)\n",
    "        ], className='mb-4'),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Vaccination Progress Across India\"),\n",
    "                    dbc.CardBody([\n",
    "                        html.Iframe(\n",
    "                            id='vax-map',\n",
    "                            srcDoc=open('vaccination_map.html', 'r').read(),\n",
    "                            style={'width': '100%', 'height': '400px'}\n",
    "                        )\n",
    "                    ])\n",
    "                ])\n",
    "            ], width=6),\n",
    "            \n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Vaccination Progress Over Time\"),\n",
    "                    dbc.CardBody([\n",
    "                        dcc.Graph(figure=vaccination_progress_chart)\n",
    "                    ])\n",
    "                ])\n",
    "            ], width=6)\n",
    "        ], className='mb-4'),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Test Positivity Rate by State\"),\n",
    "                    dbc.CardBody([\n",
    "                        dcc.Graph(figure=testing_positivity_chart)\n",
    "                    ])\n",
    "                ])\n",
    "            ], width=6),\n",
    "            \n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Vaccination vs Recovery Rate\"),\n",
    "                    dbc.CardBody([\n",
    "                        dcc.Graph(figure=recovery_vaccination_scatter)\n",
    "                    ])\n",
    "                ])\n",
    "            ], width=6)\n",
    "        ], className='mb-4'),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Cases by Age Group\"),\n",
    "                    dbc.CardBody([\n",
    "                        dcc.Graph(figure=age_distribution_chart)\n",
    "                    ])\n",
    "                ])\n",
    "            ], width=12)\n",
    "        ], className='mb-4'),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Detailed State Metrics\"),\n",
    "                    dbc.CardBody([\n",
    "                        dcc.Graph(figure=state_metrics_table)\n",
    "                    ])\n",
    "                ])\n",
    "            ], width=12)\n",
    "        ], className='mb-4')\n",
    "    ], fluid=True)\n",
    "    \n",
    "    return app\n",
    "\n",
    "# Main function to run the dashboard\n",
    "if __name__ == '__main__':\n",
    "    app = create_dashboard()\n",
    "    app.run(debug=True)\n",
    "    \n",
    "    print(\"Dashboard is running. Open http://127.0.0.1:8050/ in your web browser to view it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f31ddeeb-bcec-49ad-9088-e112f3f9e210",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'TotalSamples'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Users\\me\\anaconda3\\envs\\sat_env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'TotalSamples'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m testing_wave2 \u001b[38;5;241m=\u001b[39m testing_data[(testing_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m start_date) \u001b[38;5;241m&\u001b[39m (testing_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m end_date)]\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Create and display the chart\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m create_testing_positivity_chart(testing_wave2)\n",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m, in \u001b[0;36mcreate_testing_positivity_chart\u001b[1;34m(testing_data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_testing_positivity_chart\u001b[39m(testing_data):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Calculate positivity rate\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     testing_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPositivity_Rate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (testing_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPositive\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m testing_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotalSamples\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Group by state and calculate average positivity rate\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     state_positivity \u001b[38;5;241m=\u001b[39m testing_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPositivity_Rate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[1;32mD:\\Users\\me\\anaconda3\\envs\\sat_env\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mD:\\Users\\me\\anaconda3\\envs\\sat_env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'TotalSamples'"
     ]
    }
   ],
   "source": [
    "def create_testing_positivity_chart(testing_data):\n",
    "    # Calculate positivity rate\n",
    "    testing_data['Positivity_Rate'] = (testing_data['Positive'] / testing_data['TotalSamples']) * 100\n",
    "    \n",
    "    # Group by state and calculate average positivity rate\n",
    "    state_positivity = testing_data.groupby('State')['Positivity_Rate'].mean().reset_index()\n",
    "    state_positivity = state_positivity.sort_values('Positivity_Rate', ascending=False)\n",
    "    \n",
    "    # Create bar chart\n",
    "    fig = px.bar(\n",
    "        state_positivity.head(15),  # Top 15 states\n",
    "        x='State',\n",
    "        y='Positivity_Rate',\n",
    "        title='Average COVID-19 Test Positivity Rate by State (Second Wave)',\n",
    "        color='Positivity_Rate',\n",
    "        color_continuous_scale='Reds',\n",
    "        labels={'Positivity_Rate': 'Positivity Rate (%)'}\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_title='State',\n",
    "        yaxis_title='Positivity Rate (%)',\n",
    "        xaxis={'categoryorder':'total descending'},\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    # Option 1: Show the figure interactively (if in notebook or interactive environment)\n",
    "    fig.show()\n",
    "    \n",
    "    # Option 2: Save the figure to an HTML file\n",
    "    fig.write_html(\"test_positivity_chart.html\")\n",
    "    \n",
    "    # Option 3: Return the figure for use in a dashboard\n",
    "    return fig\n",
    "\n",
    "# If you're running this function outside of a dashboard:\n",
    "if __name__ == \"__main__\":\n",
    "    # Load testing data\n",
    "    testing_data = pd.read_csv('Statewise Testing Details_Full Data_data.csv')\n",
    "    testing_data['Date'] = pd.to_datetime(testing_data['Date'])\n",
    "    \n",
    "    # Filter for second wave period\n",
    "    start_date = '2021-03-01'\n",
    "    end_date = '2021-06-30'\n",
    "    testing_wave2 = testing_data[(testing_data['Date'] >= start_date) & (testing_data['Date'] <= end_date)]\n",
    "    \n",
    "    # Create and display the chart\n",
    "    create_testing_positivity_chart(testing_wave2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f32cdc6e-172a-44c8-a293-3ebd8cd37199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State\n",
       "Uttar Pradesh    69\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data['State'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae12aec3-cb7d-40c6-afb2-ca3911796051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State\n",
       "Kerala                                      497\n",
       "West Bengal                                 493\n",
       "Haryana                                     492\n",
       "Odisha                                      492\n",
       "Madhya Pradesh                              492\n",
       "Rajasthan                                   491\n",
       "Tamil Nadu                                  491\n",
       "Uttarakhand                                 491\n",
       "Karnataka                                   491\n",
       "Punjab                                      491\n",
       "Uttar Pradesh                               490\n",
       "Jammu and Kashmir                           489\n",
       "Delhi                                       489\n",
       "Bihar                                       489\n",
       "Himachal Pradesh                            488\n",
       "Andhra Pradesh                              488\n",
       "Maharashtra                                 488\n",
       "Gujarat                                     487\n",
       "Jharkhand                                   484\n",
       "Nagaland                                    484\n",
       "Goa                                         483\n",
       "Chhattisgarh                                482\n",
       "Chandigarh                                  479\n",
       "Puducherry                                  478\n",
       "Arunachal Pradesh                           477\n",
       "Assam                                       469\n",
       "Mizoram                                     465\n",
       "Andaman and Nicobar Islands                 453\n",
       "Tripura                                     447\n",
       "Telangana                                   419\n",
       "Sikkim                                      413\n",
       "Meghalaya                                   409\n",
       "Manipur                                     406\n",
       "Ladakh                                      294\n",
       "Lakshadweep                                 195\n",
       "Dadra and Nagar Haveli and Daman and Diu    170\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"StatewiseTestingDetails.csv\")\n",
    "df_test['State'].value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfae7838-e85d-4dc8-9e09-dfc5c8e069a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>State</th>\n",
       "      <th>TotalSamples</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Positivity_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>1210</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.855310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-24</td>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>2679.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.007839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-27</td>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>2848.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.158708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>3754.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.879062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>6677.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.494234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                        State  TotalSamples Negative  Positive  \\\n",
       "0  2020-04-17  Andaman and Nicobar Islands        1403.0     1210      12.0   \n",
       "1  2020-04-24  Andaman and Nicobar Islands        2679.0      NaN      27.0   \n",
       "2  2020-04-27  Andaman and Nicobar Islands        2848.0      NaN      33.0   \n",
       "3  2020-05-01  Andaman and Nicobar Islands        3754.0      NaN      33.0   \n",
       "4  2020-05-16  Andaman and Nicobar Islands        6677.0      NaN      33.0   \n",
       "\n",
       "   Positivity_Rate  \n",
       "0         0.855310  \n",
       "1         1.007839  \n",
       "2         1.158708  \n",
       "3         0.879062  \n",
       "4         0.494234  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_test.columns\n",
    "df_test['Positivity_Rate'] = (df_test['Positive'] / df_test['TotalSamples']) * 100\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39d7d886-b1ab-4a2b-8e0e-53915dbb83b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_testing_positivity_chart(testing_data):\n",
    "    print(f\"Original testing data shape: {testing_data.shape}\")\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(f\"Missing values in key columns:\")\n",
    "    print(f\"Positive: {testing_data['Positive'].isna().sum()}\")\n",
    "    print(f\"Total Samples: {testing_data['Total Samples'].isna().sum()}\")\n",
    "    print(f\"State: {testing_data['State'].isna().sum()}\")\n",
    "    \n",
    "    # Remove rows with missing data\n",
    "    testing_data = testing_data.dropna(subset=['Positive', 'Total Samples', 'State'])\n",
    "    print(f\"Testing data shape after removing NaNs: {testing_data.shape}\")\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    testing_data = testing_data[testing_data['Total Samples'] > 0]\n",
    "    print(f\"Testing data shape after removing zeros: {testing_data.shape}\")\n",
    "    \n",
    "    # Calculate positivity rate\n",
    "    testing_data['Positivity_Rate'] = (testing_data['Positive'] / testing_data['Total Samples']) * 100\n",
    "    \n",
    "    # Group by state and calculate average positivity rate\n",
    "    state_positivity = testing_data.groupby('State')['Positivity_Rate'].mean().reset_index()\n",
    "    state_positivity = state_positivity.sort_values('Positivity_Rate', ascending=False)\n",
    "    \n",
    "    print(f\"Number of states with positivity data: {len(state_positivity)}\")\n",
    "    print(\"Top 5 states by positivity rate:\")\n",
    "    print(state_positivity.head(5))\n",
    "    \n",
    "    if len(state_positivity) == 0:\n",
    "        print(\"ERROR: No data available to create chart!\")\n",
    "        return None\n",
    "    \n",
    "    # Create bar chart\n",
    "    fig = px.bar(\n",
    "        state_positivity.head(15),  # Top 15 states\n",
    "        x='State',\n",
    "        y='Positivity_Rate',\n",
    "        title='Average COVID-19 Test Positivity Rate by State (Second Wave)',\n",
    "        color='Positivity_Rate',\n",
    "        color_continuous_scale='Reds',\n",
    "        labels={'Positivity_Rate': 'Positivity Rate (%)'}\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_title='State',\n",
    "        yaxis_title='Positivity Rate (%)',\n",
    "        xaxis={'categoryorder':'total descending'},\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1f00d1d-a4c2-4bd1-9aba-c393a75d0ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original testing data shape: (0, 5)\n",
      "Missing values in key columns:\n",
      "Positive: 0\n",
      "Total Samples: 0\n",
      "State: 0\n",
      "Testing data shape after removing NaNs: (0, 5)\n",
      "Testing data shape after removing zeros: (0, 5)\n",
      "Number of states with positivity data: 0\n",
      "Top 5 states by positivity rate:\n",
      "Empty DataFrame\n",
      "Columns: [State, Positivity_Rate]\n",
      "Index: []\n",
      "ERROR: No data available to create chart!\n"
     ]
    }
   ],
   "source": [
    "testing_data = pd.read_csv('Statewise Testing Details_Full Data_data.csv')\n",
    "testing_data['Date'] = pd.to_datetime(testing_data['Date'])\n",
    "\n",
    "# Filter for second wave period\n",
    "start_date = '2021-03-01'\n",
    "end_date = '2021-06-30'\n",
    "testing_wave2 = testing_data[(testing_data['Date'] >= start_date) & (testing_data['Date'] <= end_date)]\n",
    "\n",
    "# Create and display the chart\n",
    "create_testing_positivity_chart(testing_wave2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d2585b-7eb8-474c-b1d0-de18fef921d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55fdc4a9-0233-415d-9968-42ca414c2e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: dash_tools in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: dash>=2.5.1 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash_tools) (3.0.2)\n",
      "Requirement already satisfied: dash-bootstrap-components in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash_tools) (2.0.0)\n",
      "Requirement already satisfied: Flask in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash_tools) (3.0.3)\n",
      "Requirement already satisfied: gunicorn in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash_tools) (23.0.0)\n",
      "Requirement already satisfied: packaging==21.3 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash_tools) (21.3)\n",
      "Requirement already satisfied: pipreqs==0.4.12 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash_tools) (0.4.12)\n",
      "Requirement already satisfied: pre-commit==2.16.0 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash_tools) (2.16.0)\n",
      "Requirement already satisfied: pytest==6.2.5 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash_tools) (6.2.5)\n",
      "Requirement already satisfied: pandas in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash_tools) (2.2.3)\n",
      "Requirement already satisfied: yolk3k==0.9 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash_tools) (0.9)\n",
      "Requirement already satisfied: termcolor==1.1.0 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash_tools) (1.1.0)\n",
      "Requirement already satisfied: visdcc==0.0.50 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash_tools) (0.0.50)\n",
      "Requirement already satisfied: dash-mantine-components==0.12.0 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash_tools) (0.12.0)\n",
      "Requirement already satisfied: dash-iconify==0.1.2 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash_tools) (0.1.2)\n",
      "Requirement already satisfied: ruamel.yaml==0.17.21 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash_tools) (0.17.21)\n",
      "Requirement already satisfied: setuptools>=65.5.1 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash_tools) (75.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from packaging==21.3->dash_tools) (3.2.1)\n",
      "Requirement already satisfied: docopt in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from pipreqs==0.4.12->dash_tools) (0.6.2)\n",
      "Requirement already satisfied: yarg in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from pipreqs==0.4.12->dash_tools) (0.1.10)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from pre-commit==2.16.0->dash_tools) (3.4.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from pre-commit==2.16.0->dash_tools) (2.6.9)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from pre-commit==2.16.0->dash_tools) (1.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from pre-commit==2.16.0->dash_tools) (6.0.2)\n",
      "Requirement already satisfied: toml in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from pre-commit==2.16.0->dash_tools) (0.10.2)\n",
      "Requirement already satisfied: virtualenv>=20.0.8 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from pre-commit==2.16.0->dash_tools) (20.30.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from pytest==6.2.5->dash_tools) (24.3.0)\n",
      "Requirement already satisfied: iniconfig in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from pytest==6.2.5->dash_tools) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from pytest==6.2.5->dash_tools) (1.5.0)\n",
      "Requirement already satisfied: py>=1.8.2 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from pytest==6.2.5->dash_tools) (1.11.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from pytest==6.2.5->dash_tools) (1.4.0)\n",
      "Requirement already satisfied: colorama in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from pytest==6.2.5->dash_tools) (0.4.6)\n",
      "Requirement already satisfied: Werkzeug<3.1 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash>=2.5.1->dash_tools) (3.0.6)\n",
      "Requirement already satisfied: plotly>=5.0.0 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash>=2.5.1->dash_tools) (6.0.1)\n",
      "Requirement already satisfied: importlib-metadata in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash>=2.5.1->dash_tools) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash>=2.5.1->dash_tools) (4.12.2)\n",
      "Requirement already satisfied: requests in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash>=2.5.1->dash_tools) (2.32.3)\n",
      "Requirement already satisfied: retrying in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash>=2.5.1->dash_tools) (1.3.4)\n",
      "Requirement already satisfied: nest-asyncio in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from dash>=2.5.1->dash_tools) (1.6.0)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from Flask->dash_tools) (3.1.5)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from Flask->dash_tools) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from Flask->dash_tools) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from Flask->dash_tools) (1.9.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from pandas->dash_tools) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from pandas->dash_tools) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from pandas->dash_tools) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from pandas->dash_tools) (2025.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from Jinja2>=3.1.2->Flask->dash_tools) (3.0.2)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from plotly>=5.0.0->dash>=2.5.1->dash_tools) (1.33.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->dash_tools) (1.16.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from virtualenv>=20.0.8->pre-commit==2.16.0->dash_tools) (0.3.9)\n",
      "Requirement already satisfied: filelock<4,>=3.12.2 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from virtualenv>=20.0.8->pre-commit==2.16.0->dash_tools) (3.18.0)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from virtualenv>=20.0.8->pre-commit==2.16.0->dash_tools) (3.10.0)\n",
      "Requirement already satisfied: zipp>=3.20 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from importlib-metadata->dash>=2.5.1->dash_tools) (3.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from requests->dash>=2.5.1->dash_tools) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from requests->dash>=2.5.1->dash_tools) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from requests->dash>=2.5.1->dash_tools) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\users\\me\\anaconda3\\envs\\sat_env\\lib\\site-packages (from requests->dash>=2.5.1->dash_tools) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (D:\\Users\\me\\anaconda3\\envs\\sat_env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~otebook (D:\\Users\\me\\anaconda3\\envs\\sat_env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (D:\\Users\\me\\anaconda3\\envs\\sat_env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~otebook (D:\\Users\\me\\anaconda3\\envs\\sat_env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (D:\\Users\\me\\anaconda3\\envs\\sat_env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~otebook (D:\\Users\\me\\anaconda3\\envs\\sat_env\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install dash_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b710e287-f396-4c99-aa82-18793fb901c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyngrok import ngrok\n",
    "\n",
    "# Open a tunnel on the default port 80\n",
    "public_url = ngrok.connect(8000)\n",
    "print(public_url)\n",
    "\n",
    "# Keep your server running\n",
    "# Your server code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7be681c5-ea92-4b63-962e-1dc8e9ad50bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dash_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdash\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependencies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, Output\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdash_tools\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# # Create sample dashboard\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# app = dash.Dash(__name__)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# Method 1: Using dash-tools\u001b[39;00m\n\u001b[0;32m     54\u001b[0m dash_tools\u001b[38;5;241m.\u001b[39mwrite_html(\n\u001b[0;32m     55\u001b[0m     app\u001b[38;5;241m=\u001b[39mapp,\n\u001b[0;32m     56\u001b[0m     html_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdashboard_static.html\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     57\u001b[0m     serve_locally\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# Include all assets locally\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     include_dash_source\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Include Dash's JS source\u001b[39;00m\n\u001b[0;32m     59\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dash_tools'"
     ]
    }
   ],
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_tools\n",
    "\n",
    "# # Create sample dashboard\n",
    "# app = dash.Dash(__name__)\n",
    "\n",
    "# # Sample data\n",
    "# df = pd.DataFrame({\n",
    "#     'Category': ['A', 'B', 'C', 'D'],\n",
    "#     'Values': [40, 20, 35, 25]\n",
    "# })\n",
    "\n",
    "# # Build dashboard layout\n",
    "# app.layout = html.Div([\n",
    "#     html.H1(\"Sample Dashboard\"),\n",
    "    \n",
    "#     html.Div([\n",
    "#         html.Label(\"Select Chart Type:\"),\n",
    "#         dcc.Dropdown(\n",
    "#             id='chart-type',\n",
    "#             options=[\n",
    "#                 {'label': 'Bar Chart', 'value': 'bar'},\n",
    "#                 {'label': 'Pie Chart', 'value': 'pie'}\n",
    "#             ],\n",
    "#             value='bar'\n",
    "#         ),\n",
    "#     ], style={'width': '30%', 'margin': '20px'}),\n",
    "    \n",
    "#     dcc.Graph(id='main-graph')\n",
    "# ])\n",
    "\n",
    "# # Define callback\n",
    "# @app.callback(\n",
    "#     Output('main-graph', 'figure'),\n",
    "#     [Input('chart-type', 'value')]\n",
    "# )\n",
    "# def update_graph(chart_type):\n",
    "#     if chart_type == 'bar':\n",
    "#         fig = px.bar(df, x='Category', y='Values', title='Bar Chart')\n",
    "#     else:\n",
    "#         fig = px.pie(df, values='Values', names='Category', title='Pie Chart')\n",
    "#     return fig\n",
    "\n",
    "# Save the dashboard as static HTML\n",
    "# if __name__ == '__main__':\n",
    "    # First install dash-tools if not already installed\n",
    "    # pip install dash-tools\n",
    "    \n",
    "    # Method 1: Using dash-tools\n",
    "dash_tools.write_html(\n",
    "    app=app,\n",
    "    html_file=\"dashboard_static.html\",\n",
    "    serve_locally=True,  # Include all assets locally\n",
    "    include_dash_source=True  # Include Dash's JS source\n",
    ")\n",
    "\n",
    "print(\"Dashboard saved as 'dashboard_static.html'\")\n",
    "    \n",
    "    # # Method 2: Alternative approach using a headless browser\n",
    "    # # Requires installation of selenium and webdriver\n",
    "    # \"\"\"\n",
    "    # from selenium import webdriver\n",
    "    # import time\n",
    "    \n",
    "    # # Start the Dash app in a separate thread\n",
    "    # import threading\n",
    "    # threading.Thread(target=app.run_server, kwargs={'debug': False, 'port': 8050}).start()\n",
    "    \n",
    "    # # Use headless browser to capture the rendered page\n",
    "    # options = webdriver.ChromeOptions()\n",
    "    # options.add_argument('--headless')\n",
    "    # driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "    # # Wait for the page to load\n",
    "    # time.sleep(3)\n",
    "    # driver.get('http://localhost:8050')\n",
    "    # time.sleep(5)  # Give time for all elements to render\n",
    "    \n",
    "    # # Get the page source\n",
    "    # html_content = driver.page_source\n",
    "    \n",
    "    # # Save to file\n",
    "    # with open('dashboard_static_selenium.html', 'w', encoding='utf-8') as f:\n",
    "    #     f.write(html_content)\n",
    "    \n",
    "    # driver.quit()\n",
    "    # print(\"Dashboard saved as 'dashboard_static_selenium.html'\")\n",
    "    # \"\"\"\n",
    "    \n",
    "    # You can also run the app normally\n",
    "    # app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54331ae-40cc-4db5-ba5e-e53359cb36ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sat_env",
   "language": "python",
   "name": "sat_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
